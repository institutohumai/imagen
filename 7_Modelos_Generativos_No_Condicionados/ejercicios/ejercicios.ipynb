{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/CV/7_Modelos_Generativos/ejercicios/ejercicios.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"
      ],
      "metadata": {
        "id": "JkO1fJA8Y1Ll"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-title"
        ],
        "id": "1K6AFetG4fKj"
      },
      "source": [
        "# Ejercicios Clase 7\n",
        "\n",
        "Hasta ahora, todas las aplicaciones de las redes neuronales que hemos explorado han sido **modelos discriminativos** que toman una entrada y están entrenados para producir una salida etiquetada. En este notebook, vamos a ampliar nuestro repertorio al crear **modelos generativos** utilizando redes neuronales. Específicamente, camos a aprender a construir modelos que generen imágenes novedosas que se asemejen a un conjunto de imágenes de entrenamiento.\n",
        "\n",
        "### ¿Qué es una GAN?\n",
        "\n",
        "En 2014, [Goodfellow et al.] (Https://arxiv.org/abs/1406.2661) presentó un método para entrenar modelos generativos llamado Redes Adversarias Generativas (GAN, por sus siglas en inglés). En una GAN, construimos dos redes neuronales diferentes. Nuestra primera red es una red de clasificación tradicional, llamada **discriminador**. Vamos a entrenar al discriminador para tomar imágenes y clasificarlas como reales (pertenecientes al conjunto de entrenamiento) o falsas (no presentes en el conjunto de entrenamiento). Nuestra otra red, llamada **generador**, va a tomar ruido aleatorio como entrada y lo va a transformar usando una red neuronal para producir imágenes. El objetivo del generador es engañar al discriminador haciéndole creer que las imágenes que produjo son reales.\n",
        "\n",
        "Podemos pensar en este proceso de ida y vuelta del generador ($ G $) tratando de engañar al discriminador ($ D $), y el discriminador tratando de clasificar correctamente lo real frente a lo falso como un juego minimax:\n",
        "$$\\underset{G}{\\text{minimize}}\\; \\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
        "donde $ z \\sim p (z) $ son las muestras de ruido aleatorias, $ G (z) $ son las imágenes generadas usando el generador $ G $ y $ D() $ es la salida del discriminador, especificando la probabilidad de que una entrada sea real.  En [Goodfellow et al.] (Https://arxiv.org/abs/1406.2661), analizan este juego minimax y muestran cómo se relaciona con minimizar la divergencia Jensen-Shannon entre la distribución de datos de entrenamiento y las muestras generadas a partir de $ G $\n",
        "\n",
        "Para optimizar este juego minimax, alternaremos entre tomar pasos de gradiente * descendiente * en la función de pérdida de $ G $ y pasos de gradiente * ascendiente * en la función de pérdida de $ D $:\n",
        "1. Actualizar el **generador** ($ G $) para minimizar la probabilidad de que el __discriminador tome la decisión correcta__.\n",
        "2. Actualizar el **discriminador** ($ D $) para maximizar la probabilidad de que el __discriminador tome la decisión correcta__.\n",
        "\n",
        "Si bien estas actualizaciones son útiles para el análisis, no funcionan bien en la práctica. En cambio, usaremos un objetivo diferente cuando actualicemos el generador: maximizar la probabilidad de que el ** discriminador haga la elección incorrecta **. Este pequeño cambio ayuda a aliviar los problemas con la desaparición del gradiente del generador cuando el discriminador tiene confianza. Esta es la actualización estándar utilizada en la mayoría de los artículos de GAN y se utilizó en el artículo original de [Goodfellow et al.] (Https://arxiv.org/abs/1406.2661).\n",
        "\n",
        "\n",
        "En este práctico, alternaremos entre las siguientes actualizaciones:\n",
        "1. Actualizar el generador ($ G $) para maximizar la probabilidad de que el discriminador haga la elección incorrecta en los datos generados:\n",
        "$$\\underset{G}{\\text{maximize}}\\;  \\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
        "2. Actualizar el discriminador ($ D $), para maximizar la probabilidad de que el discriminador haga la elección correcta en datos reales y generados: \n",
        "$$\\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
        "\n",
        "### ¿Qué más hay para ver?\n",
        "Desde 2014, las GAN se han convertido en un área de investigación enorme, con [talleres educacionales] masivos (https://sites.google.com/site/nips2016adversarial/) y [cientos de artículos nuevos] (https://github.com/ hindupuravinash / the-gan-zoo). En comparación con otros enfoques para modelos generativos, a menudo producen muestras de la más alta calidad, pero son algunos de los modelos más difíciles y meticulosos de entrenar (consulte [este repositorio de github] (https://github.com/soumith/ganhacks) que contiene un conjunto de 17 trucos útiles para que los modelos funcionen). Mejorar la estabilidad y solidez de la formación GAN es una cuestión de investigación abierta, ¡con nuevos artículos que salen todos los días! Para obtener un tutorial más reciente sobre GAN, consulte [aquí] (https://arxiv.org/abs/1701.00160). También hay un trabajo emocionante aún más reciente que cambia la función objetivo a la distancia de Wasserstein y produce resultados mucho más estables en las arquitecturas de modelos: [WGAN] (https://arxiv.org/abs/1701.07875), [WGAN-GP] ( https://arxiv.org/abs/1704.00028).\n",
        "\n",
        "\n",
        "¡Las GAN no son la única forma de entrenar un modelo generativo! Para conocer otros enfoques del modelado generativo, consulte el [capítulo sobre el modelo generativo profundo] (http://www.deeplearningbook.org/contents/generative_models.html) del [libro] de aprendizaje profundo (http://www.deeplearningbook.org) . Otra forma popular de entrenar redes neuronales como modelos generativos son los autocodificadores automáticos variacionales (VAE por sus siglas en inglés) (co-descubierto [aquí] (https://arxiv.org/abs/1312.6114) y [aquí] (https://arxiv.org/abs/1401.4082) ). Los autocodificadores variacionales combinan redes neuronales con inferencia variacional para entrenar modelos generativos profundos. Estos modelos tienden a ser mucho más estables y fáciles de entrenar, pero actualmente no producen muestras tan bonitas como las GAN.\n",
        "\n",
        "Aquí hay un ejemplo de cómo deberían verse sus resultados de los 3 modelos diferentes que va a entrenar ... tenga en cuenta que las GAN a veces son meticulosas, por lo que es posible que sus resultados no se vean exactamente así ... esto solo está destinado a ser un *guía aproximada* del tipo de calidad que puede esperar:\n",
        "\n",
        "![An image](https://i.imgur.com/y56vi1g.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "1DOYf8o44fKk"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDfzazLqTI7C"
      },
      "source": [
        "En esta sección vamos a importar todos los módulos necesarios y a definir algunas funciones que nos van a ser útiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "DE1ExABn4fKm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK5x05PYTG0p"
      },
      "source": [
        "def show_images(images):\n",
        "    images = np.reshape(images, [images.shape[0], -1])\n",
        "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
        "    return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUSIi1l3Sv_B"
      },
      "source": [
        "def preprocess_img(x):\n",
        "    return 2 * x - 1.0\n",
        "\n",
        "def deprocess_img(x):\n",
        "    return (x + 1.0) / 2.0\n",
        "\n",
        "def rel_error(x,y):\n",
        "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
        "\n",
        "def count_params(model):\n",
        "    \"\"\"Cuenta la cantidad de parámteros presentes en el grafo computacional \"\"\"\n",
        "    param_count = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
        "    return param_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6EPcYszUEfO"
      },
      "source": [
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset. \n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start=0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7BTfDlR4fKo"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1WMVK8XB1FZiMNA0Y4U1X2gBonmJOAdk_\n",
        "answers = dict(np.load('gan-checks-tf.npz'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "6QOuxY564fKo"
      },
      "source": [
        "## Dataset\n",
        "Las GAN son notoriamente meticulosas con los hiperparámetros y también requieren muchas épocas de entrenamiento. Para que esta tarea sea accesible para un trabajo práctico, trabajaremos en el conjunto de datos MNIST, que consta de 60.000 imágenes de entrenamiento y 10.000 imágenes de prueba. Cada imagen contiene una imagen centrada de dígitos blancos sobre fondo negro (0 a 9). Este fue uno de los primeros conjuntos de datos utilizados para entrenar redes neuronales convolucionales y es bastante fácil de resolver: un modelo CNN estándar puede superar fácilmente el 99% de precisión.\n",
        "\n",
        "Para simplificar nuestro código aquí, usaremos el contenedor PyTorch MNIST, que descarga y carga el conjunto de datos MNIST. Consulte la [documentación] (https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) para obtener más información sobre la interfaz. Los parámetros predeterminados tomarán 5,000 de los ejemplos de entrenamiento y los colocarán en un conjunto de datos de validación. Los datos se guardarán en una carpeta llamada `MNIST_data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "tags": [
          "pdf-ignore"
        ],
        "id": "7Izxy5jZ4fKp"
      },
      "source": [
        "NUM_TRAIN = 50000\n",
        "NUM_VAL = 5000\n",
        "\n",
        "NOISE_DIM = 96\n",
        "batch_size = 128\n",
        "\n",
        "mnist_train = dset.MNIST('./cs231n/datasets/MNIST_data', train=True, download=True,\n",
        "                           transform=T.ToTensor())\n",
        "loader_train = DataLoader(mnist_train, batch_size=batch_size,\n",
        "                          sampler=ChunkSampler(NUM_TRAIN, 0))\n",
        "\n",
        "mnist_val = dset.MNIST('./cs231n/datasets/MNIST_data', train=True, download=True,\n",
        "                           transform=T.ToTensor())\n",
        "loader_val = DataLoader(mnist_val, batch_size=batch_size,\n",
        "                        sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
        "\n",
        "\n",
        "imgs = loader_train.__iter__().next()[0].view(batch_size, 784).numpy().squeeze()\n",
        "show_images(imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwYLBzPO4fKq"
      },
      "source": [
        "## Ruido aleatorio\n",
        "Implemente `sample_noise` para que genere un ruido uniforme de -1 a 1 con la forma \"[batch_size, dim]\".\n",
        "\n",
        "Sugerencia: use `torch.rand`.\n",
        "\n",
        "Asegurate de que el ruido tenga la forma y el tipo correctos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eog7RWWlVLWC"
      },
      "source": [
        "NOISE_DIM = 96\n",
        "\n",
        "def sample_noise(batch_size, dim, seed=None):\n",
        "    \"\"\"\n",
        "    Genera un tensor de PyTorch con ruido aleatorio uniforme.\n",
        "\n",
        "    Entradas:\n",
        "    - batch_size: número entero que indica el tamaño del lote de ruido a generar.\n",
        "    - dim: número entero que da la dimensión del ruido a generar.\n",
        "\n",
        "    Salidas:\n",
        "    - Un tensor de PyTorch con forma (batch_size, dim) que contiene ruido aleatorio\n",
        "    uniforme en el rango (-1, 1).\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        \n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sample_noise_test"
      },
      "source": [
        "def test_sample_noise(): \n",
        "    batch_size = 3\n",
        "    dim = 4\n",
        "    torch.manual_seed(231)\n",
        "    z = sample_noise(batch_size, dim)\n",
        "    np_z = z.cpu().numpy()\n",
        "    assert np_z.shape == (batch_size, dim)\n",
        "    assert torch.is_tensor(z)\n",
        "    assert np.all(np_z >= -1.0) and np.all(np_z <= 1.0)\n",
        "    assert np.any(np_z < 0.0) and np.any(np_z > 0.0)\n",
        "    print('Su código superó todos los tests realizados!')\n",
        "    \n",
        "test_sample_noise()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "SQNIH5iI4fKr"
      },
      "source": [
        "## Flatten\n",
        "\n",
        "Proporcionamos una función Flatten y Unflatten, que pueden ser utilizadas al implementar el generador convolucional. También proporcionamos un inicializador de pesos que usa la inicialización de Xavier en lugar del uniforme predeterminado de PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "AE2_Zwl54fKs"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size() # \n",
        "        return x.view(N, -1)  # \"aplasta\" los valores de C * H * W en un solo vector por imagen\n",
        "    \n",
        "class Unflatten(nn.Module):\n",
        "    \"\"\"\n",
        "    Recibe una entrada de forma (N, C * H * W) y la reforma para producir una\n",
        "    salida de forma (N, C, H, W). \n",
        "    \"\"\"\n",
        "    def __init__(self, N=-1, C=128, H=7, W=7):\n",
        "        super(Unflatten, self).__init__()\n",
        "        self.N = N\n",
        "        self.C = C\n",
        "        self.H = H\n",
        "        self.W = W\n",
        "    def forward(self, x):\n",
        "        return x.view(self.N, self.C, self.H, self.W)\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "icBqoF5e4fKs"
      },
      "source": [
        "## CPU / GPU\n",
        "De forma predeterminada, todo el código se ejecutará en la CPU. No se necesitan GPU para esta tarea, pero te ayudarán a entrenar tus modelos más rápido. Si querés ejecutar el código en una GPU, cambiá la variable `dtype` en la siguiente celda.\n",
        "** Si estás en Colab, se recomienda cambiar el tiempo de ejecución de colab a GPU. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "W0SCvMnz4fKs"
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "#dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8WYW6dE4fKt"
      },
      "source": [
        "# Discriminador\n",
        "Nuestro primer paso es construir un discriminador. Complete la arquitectura como parte del constructor `nn.Sequential` en la función siguiente. Todas las capas densas deben incluir términos de bias. La arquitectura es:\n",
        "  * Capa densa con tamaño de entrada 784 y tamaño de salida 256\n",
        "  * LeakyReLU con alfa 0.01\n",
        "  * Capa densa con input_size 256 y output size 256\n",
        "  * LeakyReLU con alfa 0.01\n",
        "  * Capa densa con tamaño de entrada 256 y tamaño de salida 1\n",
        " \n",
        "Recuerde que la no linealidad de ReLU con fugas calcula $ f (x) = \\max (\\alpha x, x) $ para alguna constante fija $ \\alpha $; para las no linealidades de LeakyReLU en la arquitectura anterior, establecemos $ \\alpha = 0.01 $.\n",
        " \n",
        "La salida del discriminador debe tener la forma `[batch_size, 1]`, y contener números reales correspondientes a las puntuaciones de que cada una de las entradas de `batch_size` es una imagen real.\n",
        "\n",
        "Implementar `discriminator` en la celda siguiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BSjksGzbCgK"
      },
      "source": [
        "def discriminator(seed=None):\n",
        "    \"\"\"\n",
        "    Crea y devuelve un modelo de PyTorch que implemente la arquitectura anterior.\n",
        "    \"\"\"\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    model = None\n",
        "\n",
        "    ##############################################################################\n",
        "    # TODO: Implementá la arquitectura                                           #\n",
        "    #                                                                            #\n",
        "    # TIP: nn.Sequential puede ser útil.                                         #\n",
        "    ##############################################################################\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    ##############################################################################\n",
        "    #                               FIN DE SU CÓDIGO                            #\n",
        "    ##############################################################################\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW_p__KH4fKt"
      },
      "source": [
        "Asegurate con el siguiente código de que el número de parámetros en el discriminador sea correcto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRRZRK2m4fKt"
      },
      "source": [
        "def test_discriminator(true_count=267009):\n",
        "    model = discriminator()\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Número incorrecto de parámetros en el discriminador. Revisá tu arquitectura.')\n",
        "    else:\n",
        "        print('Número correcto de parámetros en el discriminador.') \n",
        "\n",
        "test_discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B47gm8d94fKu"
      },
      "source": [
        "# Generador\n",
        "Ahora para construir el generador con la siguiente arquitectura:\n",
        "\n",
        "  * Capa densa desde noise_dim hasta 1024\n",
        "  * `ReLU`\n",
        "  * Capa densa con tamaño 1024\n",
        "  * `ReLU`\n",
        "  * Capa densa con tamaño 784\n",
        "  * `TanH` (para formatear los valores de los píxeles de la imagen para que esté en el rango de [-1,1])\n",
        " \n",
        "  Implementar `generator` en la siguiente celda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO-Jo26q4fKu"
      },
      "source": [
        "Asegurate con el siguiente código de que el número de parámetros en el generador sea correcto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h56ww3a5VRkf"
      },
      "source": [
        "def generator(noise_dim=NOISE_DIM, seed=None):\n",
        "    \"\"\"\n",
        "    Crea y devuelve un modelo de PyTorch que implemente la arquitectura anterior.\n",
        "    \"\"\"\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    model = None\n",
        "\n",
        "    ##############################################################################\n",
        "    # TODO: Implementá la arquitectura                                           #\n",
        "    #                                                                            #\n",
        "    # TIP: nn.Sequential puede ser útil.                                         #\n",
        "    ##############################################################################\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    ##############################################################################\n",
        "    #                               FIN DE SU CÓDIGO                            #\n",
        "    ##############################################################################\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIvjJ7NJ4fKu"
      },
      "source": [
        "def test_generator(true_count=1858320):\n",
        "    model = generator(4)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Número incorrecto de parámetros en el generador. Revisá tu arquitectura.')\n",
        "    else:\n",
        "        print('Número correcto de parámetros en el generador.')\n",
        "\n",
        "test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-GEDWZ74fKv"
      },
      "source": [
        "# GAN Loss\n",
        "\n",
        "Calcule la pérdida del generador y el discriminador. La pérdida del generador es:\n",
        "$$ \\ell_G = - \\mathbb {E} _ {z \\sim p(z)} \\left [\\log D (G (z)) \\right] $$\n",
        "y la pérdida del discriminador es:\n",
        "$$ \\ell_D = - \\mathbb{E} _ {x \\sim p_ \\text {data}} \\left [\\log D (x) \\right] - \\mathbb {E} _ {z \\sim p (z) } \\left [\\log \\left (1-D (G (z)) \\right) \\right] $$\n",
        "\n",
        "Tenga en cuenta que estas son las ecuaciones presentadas anteriormente pero negadas, ya que estaremos *minimizando* estas pérdidas.\n",
        "\n",
        "**SUGERENCIA**: Debería usar la función `bce_loss` definida a continuación para calcular la pérdida de entropía cruzada binaria que se necesita para calcular la probabilidad logarítmica de la etiqueta verdadera dada la salida de logits del discriminador. Dada una puntuación $ s \\in \\mathbb {R} $ y una etiqueta $y \\in \\{0, 1 \\}$ , la pérdida de entropía cruzada binaria es\n",
        "\n",
        "$$ bce (s, y) = -y * \\log (s) - (1 - y) * \\log (1 - s) $$\n",
        "\n",
        "Una implementación ingenua de esta fórmula puede ser numéricamente inestable, por lo que a continuación le proporcionamos una implementación numéricamente estable.\n",
        "\n",
        "También necesitará calcular las etiquetas para las imágenes correspondientes a \"reales\" o \"falsas\" y usar los argumentos logit para determinar su tamaño. Asegurate de convertir estas etiquetas al tipo de datos correcto usando la variable global `dtype`, por ejemplo:\n",
        "\n",
        "\n",
        "`true_labels = torch.ones(size).type(dtype)`\n",
        "\n",
        "En lugar de calcular la esperanza de $ \\log D (G (z)) $, $ \\log D (x) $ y $ \\log \\left (1-D (G (z)) \\right) $, vamos a promediar los elementos del minibatch, así que asegurate de combinar la pérdida promediando en lugar de sumando.\n",
        "\n",
        "Implementar `bce_loss`,` discriminator_loss`, `generator_loss` en las siguientes celdas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8l41V3Gd36n"
      },
      "source": [
        "def bce_loss(input, target):\n",
        "    \"\"\"\n",
        "    Versión numéricamente estable de la función de pérdida de entropía cruzada binaria.\n",
        "    Consulte los documentos de TensorFlow para obtener una derivación de esta fórmula:\n",
        "    https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
        "\n",
        "    Entradas:\n",
        "    - input: Tensor PyTorch de forma (N, ) que contiene puntajes.\n",
        "    - target: Tensor PyTorch de forma (N, ) que contiene 0 y 1 como etiquetas.\n",
        "\n",
        "    Devuelve:\n",
        "    - Un Tensor PyTorch que contiene la pérdida media de BCE sobre el minibatch de datos de entrada.\n",
        "    \"\"\"\n",
        "    neg_abs = - input.abs()\n",
        "    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
        "    return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEi6HjU2eCwY"
      },
      "source": [
        "def discriminator_loss(logits_real, logits_fake):\n",
        "    \"\"\"\n",
        "    Calcula la pérdida del discriminador descrita anteriormente.\n",
        "    \n",
        "    Entradas:\n",
        "     - logits_real: PyTorch Tensor de forma (N,) que da puntuaciones para los datos reales.\n",
        "     - logits_fake: PyTorch Tensor de forma (N,) que da puntuaciones para los datos falsos.\n",
        "    \n",
        "    Devuelve:\n",
        "     - loss: PyTorch Tensor que contiene (escalar) la pérdida para el discriminador.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPygL5U_d_84"
      },
      "source": [
        "def generator_loss(logits_fake):\n",
        "    \"\"\"\n",
        "    Calcula la pérdida del generador descrita anteriormente.\n",
        "    \n",
        "    Entradas:\n",
        "     - logits_fake: PyTorch Tensor de forma (N,) que da puntuaciones para los datos falsos.\n",
        "    \n",
        "    Devuelve:\n",
        "     - loss: PyTorch Tensor que contiene (escalar) la pérdida para el discriminador.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywGLvLtq4fKv"
      },
      "source": [
        "Proobá la pérdida de su generador y discriminador. Debería ver errores <1e-7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ_GGGwU4fKv"
      },
      "source": [
        "def test_discriminator_loss(logits_real, logits_fake, d_loss_true):\n",
        "    d_loss = discriminator_loss(torch.Tensor(logits_real).type(dtype),\n",
        "                                torch.Tensor(logits_fake).type(dtype)).cpu().numpy()\n",
        "    print(\"Error máximo en d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
        "\n",
        "test_discriminator_loss(answers['logits_real'], answers['logits_fake'],\n",
        "                        answers['d_loss_true'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1gINLH24fKw"
      },
      "source": [
        "def test_generator_loss(logits_fake, g_loss_true):\n",
        "    g_loss = generator_loss(torch.Tensor(logits_fake).type(dtype)).cpu().numpy()\n",
        "    print(\"Error máximo en g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
        "\n",
        "test_generator_loss(answers['logits_fake'], answers['g_loss_true'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgV4wC3q4fKw"
      },
      "source": [
        "# Optimizando nuestra pérdida\n",
        "Cree una función que devuelva un optimizador `optim.Adam` para el modelo dado con una tasa de aprendizaje de 1e-3, beta1 = 0.5, beta2 = 0.999. Utilizará esto para construir optimizadores para los generadores y discriminadores para el resto del notebook.\n",
        "\n",
        "Implementar `get_optimizer` en la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckxSfwYkgK9i"
      },
      "source": [
        "def get_optimizer(model):\n",
        "    \"\"\"\n",
        "    Construya y devuelva un optimizador de Adam para el modelo con tasa de aprendizaje 1e-3,\n",
        "    beta1 = 0,5 y beta2 = 0,999.\n",
        "\n",
        "    Entrada:\n",
        "    - modelo: un modelo de PyTorch que queremos optimizar.\n",
        "\n",
        "    Devuelve:\n",
        "    - Un optimizador de Adam para el modelo con los hiperparámetros deseados.\n",
        "    \"\"\"\n",
        "    optimizer = None\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKGEgUXz4fKx"
      },
      "source": [
        "# ¡Entrenando una GAN!\n",
        "\n",
        "Te proporcionamos el ciclo de entrenamiento principal... no necesitará cambiar la función `run_a_gan` definida en la siguiente celda, pero te recomendamos que lo leás y lo entendás."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "zGCa2ZXz4fKx"
      },
      "source": [
        "def run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, loader_train, show_every=250, \n",
        "              batch_size=128, noise_size=96, num_epochs=10):\n",
        "    \"\"\"\n",
        "    ¡Entrena un GAN!\n",
        "    \n",
        "     Entradas:\n",
        "     - D, G: modelos PyTorch para discriminador y generador\n",
        "     - D_solver, G_solver: Optimizadores torch.optim usadas para entrenar\n",
        "       discriminador y generador.\n",
        "     - discriminator_loss, generator_loss: Funciones a utilizar para calcular el generador y\n",
        "       pérdida del discriminador, respectivamente.\n",
        "     - show_every: muestra ejemplos después de una cantidad de iteraciones show_every.\n",
        "     - batch_size: tamaño de lote que se utilizará para el entrenamiento.\n",
        "     - noise_size: dimensión del ruido a utilizar como entrada para el generador.\n",
        "     - num_epochs: número de épocas sobre el conjunto de datos de entrenamiento que se usarán para el entrenamiento.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    iter_count = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x, _ in loader_train:\n",
        "            if len(x) != batch_size:\n",
        "                continue\n",
        "            D_solver.zero_grad()\n",
        "            real_data = x.type(dtype)\n",
        "            logits_real = D(2* (real_data - 0.5)).type(dtype)\n",
        "\n",
        "            g_fake_seed = sample_noise(batch_size, noise_size).type(dtype)\n",
        "            fake_images = G(g_fake_seed).detach()\n",
        "            logits_fake = D(fake_images.view(batch_size, 1, 28, 28))\n",
        "\n",
        "            d_total_error = discriminator_loss(logits_real, logits_fake)\n",
        "            d_total_error.backward()        \n",
        "            D_solver.step()\n",
        "\n",
        "            G_solver.zero_grad()\n",
        "            g_fake_seed = sample_noise(batch_size, noise_size).type(dtype)\n",
        "            fake_images = G(g_fake_seed)\n",
        "\n",
        "            gen_logits_fake = D(fake_images.view(batch_size, 1, 28, 28))\n",
        "            g_error = generator_loss(gen_logits_fake)\n",
        "            g_error.backward()\n",
        "            G_solver.step()\n",
        "\n",
        "            if (iter_count % show_every == 0):\n",
        "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,d_total_error.item(),g_error.item()))\n",
        "                imgs_numpy = fake_images.data.cpu().numpy()\n",
        "                images.append(imgs_numpy[0:16])\n",
        "\n",
        "            iter_count += 1\n",
        "    \n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qjySLzGK4fKy"
      },
      "source": [
        "D = discriminator().type(dtype)\n",
        "G = generator().type(dtype)\n",
        "\n",
        "# Usá la función que escribiste anteriormente para obtener optimizadores para el Discriminador y el Generador\n",
        "D_solver = get_optimizer(D)\n",
        "G_solver = get_optimizer(G)\n",
        "# Correlo!\n",
        "images = run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, loader_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd4lTeHr4fKy"
      },
      "source": [
        "Ejecute la celda de abajo para mostrar las imágenes generadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAqKokG94fKy"
      },
      "source": [
        "numIter = 0\n",
        "for img in images:\n",
        "    print(\"Iter: {}\".format(numIter))\n",
        "    show_images(img)\n",
        "    plt.show()\n",
        "    numIter += 250\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "oapHth4Y4fKz"
      },
      "source": [
        "Bueno, eso no fue tan difícil, ¿verdad? Alrededor de las 100 iteraciones, debería ver fondos negros con formas borrosas y, a medida que se acerca a la iteración 1000, debería ver formas decentes. Aproximadamente la mitad de las imágenes serán nítidas y claramente reconocibles a medida que pasemos las 3000 iteraciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ7ODS6H4fK0"
      },
      "source": [
        "# GAN Mínimos cuadrados \n",
        "Ahora veremos [Least Squares GAN] (https://arxiv.org/abs/1611.04076), una alternativa más nueva y estable a la función de pérdida de GAN original. Para esta parte, todo lo que tenemos que hacer es cambiar la función de pérdida y reentrenar el modelo. Implementaremos la ecuación (9) en el artículo, con la pérdida del generador:\n",
        "$$ \\ell_G = \\frac {1} {2} \\mathbb {E} _ {z \\sim p (z)} \\left [\\left (D (G (z)) - 1 \\right) ^ 2 \\right ] $$\n",
        "y la pérdida del discriminador:\n",
        "$$ \\ell_D = \\frac {1} {2} \\mathbb {E} _ {x \\sim p_ \\text {data}} \\left [\\left (D (x) -1 \\right) ^ 2 \\right] + \\frac {1} {2} \\mathbb {E} _ {z \\sim p (z)} \\left [\\left (D (G (z)) \\right) ^ 2 \\right] $$\n",
        "\n",
        "\n",
        "** SUGERENCIAS **: En lugar de calcular la esperanza, estaremos promediando elementos del minibatch, así que asegúrese de combinar la pérdida promediando en lugar de sumando. Cuando conecte con $ D(x) $ y $ D(G(z)) $ use la salida directa del discriminador (`scores_real` y` scores_fake`).\n",
        "\n",
        "Implemente `ls_discriminator_loss`, `ls_generator_loss` en las siguientes celdas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svH43kSojiP3"
      },
      "source": [
        "def ls_discriminator_loss(scores_real, scores_fake):\n",
        "    \"\"\"\n",
        "    Calcula la pérdida de mínimos cuadrados para el discriminador.\n",
        "    \n",
        "    Entradas:\n",
        "     - logits_real: PyTorch Tensor de forma (N,) que da puntuaciones para los datos reales.\n",
        "     - logits_fake: PyTorch Tensor de forma (N,) que da puntuaciones para los datos falsos.\n",
        "    \n",
        "    Devuelve:\n",
        "     - loss: PyTorch Tensor que contiene (escalar) la pérdida para el discriminador.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF7e65BSjqdC"
      },
      "source": [
        "def ls_generator_loss(scores_fake):\n",
        "    \"\"\"\n",
        "    Calcula la pérdida de mínimos cuadrados para el generador.\n",
        "    \n",
        "    Entradas:\n",
        "     - logits_fake: PyTorch Tensor de forma (N,) que da puntuaciones para los datos falsos.\n",
        "    \n",
        "    Devuelve:\n",
        "     - loss: PyTorch Tensor que contiene (escalar) la pérdida para el discriminador.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGFz6aTU4fK0"
      },
      "source": [
        "Antes de ejecutar una GAN con nuestra nueva función de pérdida, vamos a probarla:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2TRwofr4fK0"
      },
      "source": [
        "def test_lsgan_loss(score_real, score_fake, d_loss_true, g_loss_true):\n",
        "    score_real = torch.Tensor(score_real).type(dtype)\n",
        "    score_fake = torch.Tensor(score_fake).type(dtype)\n",
        "    d_loss = ls_discriminator_loss(score_real, score_fake).cpu().numpy()\n",
        "    g_loss = ls_generator_loss(score_fake).cpu().numpy()\n",
        "    print(\"Error máximo en d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
        "    print(\"Error máximo en g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
        "\n",
        "test_lsgan_loss(answers['logits_real'], answers['logits_fake'],\n",
        "                answers['d_loss_lsgan_true'], answers['g_loss_lsgan_true'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkoDJWcw4fK1"
      },
      "source": [
        "Corré la siguiente celda para entrenar tu modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "iS-4lB7i4fK1"
      },
      "source": [
        "D_LS = discriminator().type(dtype)\n",
        "G_LS = generator().type(dtype)\n",
        "\n",
        "D_LS_solver = get_optimizer(D_LS)\n",
        "G_LS_solver = get_optimizer(G_LS)\n",
        "\n",
        "images = run_a_gan(D_LS, G_LS, D_LS_solver, G_LS_solver, ls_discriminator_loss, ls_generator_loss, loader_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09RMOi6a4fK1"
      },
      "source": [
        "Corré la siguiente celda para mostrar las imágenes generados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If8Cp-974fK1"
      },
      "source": [
        "numIter = 0\n",
        "for img in images:\n",
        "    print(\"Iter: {}\".format(numIter))\n",
        "    show_images(img)\n",
        "    plt.show()\n",
        "    numIter += 250\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzNJDb8U4fK1"
      },
      "source": [
        "**Por favor adjunte en esta celda las imagenes generadas para la corrección del práctico.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg2ne1kK4fK2"
      },
      "source": [
        "# GANs profundamente convolucionales\n",
        "En la primera parte del notebook, implementamos una copia casi directa de la red GAN original de Ian Goodfellow. Sin embargo, esta arquitectura de red no permite un razonamiento espacial real. Es incapaz de razonar sobre cosas como \"bordes afilados\" en general porque carece de capas convolucionales. Así, en esta sección, implementaremos algunas de las ideas de [DCGAN](https://arxiv.org/abs/1511.06434), donde usamos redes convolucionales\n",
        "\n",
        "#### Discriminador\n",
        "Usaremos un discriminador inspirado en el tutorial de clasificación MNIST de TensorFlow, que puede obtener una precisión superior al 99% en el conjunto de datos MNIST con bastante rapidez.\n",
        "* Cambiá la forma para que sea un tensor de imágenes (¡Usá Unflatten!)\n",
        "* Conv2D: 32 filtros, 5x5, Stride 1\n",
        "* Leaky ReLU((alfa = 0,01)\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Conv2D: 64 filtros, 5x5, Stride 1\n",
        "* Leaky ReLU((alfa = 0,01)\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Flatten\n",
        "* Capa densa con 4 x 4 x 64 neuronas\n",
        "* Leaky ReLU((alfa = 0,01)\n",
        "* Capa densa con 1 neurona\n",
        "\n",
        "Implementá `build_dc_classifier` en` la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkN4AiHkm_8A"
      },
      "source": [
        "def build_dc_classifier(batch_size):\n",
        "    \"\"\"\n",
        "    Crea y devuelve un modelo PyTorch para el discriminador DCGAN que implementa\n",
        "    la arquitectura anterior.\n",
        "    \"\"\"\n",
        "    ##############################################################################\n",
        "    # TODO: Implementá la arquitectura                                           #\n",
        "    #                                                                            #\n",
        "    # TIP: nn.Sequential puede ser útil.                                         #\n",
        "    ##############################################################################\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    ##############################################################################\n",
        "    #                               FIN DE SU CÓDIGO                            #\n",
        "    ##############################################################################\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbw7OGIQ4fK2"
      },
      "source": [
        "data = next(enumerate(loader_train))[-1][0].type(dtype)\n",
        "b = build_dc_classifier(batch_size).type(dtype)\n",
        "out = b(data)\n",
        "print(out.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A0xEuAG4fK2"
      },
      "source": [
        "Verificá la cantidad de parámetros en tu clasificador por las dudas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0eVaheX4fK2"
      },
      "source": [
        "def test_dc_classifer(true_count=1102721):\n",
        "    model = build_dc_classifier(batch_size)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Número incorrecto de parámetros en el clasificador. Revisá tu arquitectura.')\n",
        "    else:\n",
        "        print('Número correcto de parámetros en el clasificador.')\n",
        "\n",
        "test_dc_classifer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1lBYbyt4fK2"
      },
      "source": [
        "#### Generador\n",
        "Para el generador, copiaremos la arquitectura exactamente del [documento de InfoGAN](https://arxiv.org/pdf/1606.03657.pdf). Consulte el Apéndice C.1 MNIST. Consulte la documentación de [tf.nn.conv2d_transpose](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose). Siempre estamos \"entrenando\" en modo GAN.\n",
        "* Capa densa con 1024 neuronas\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Capa densa con 7 x 7 x 128 neuronas\n",
        "* ReLU\n",
        "* BatchNorm\n",
        "* Transformar la salida en un tensor de imagen de la forma (7, 7, 128)\n",
        "* Conv2D ^ T (Transpuesta): 64 filtros de 4x4, stride 2,`padding = 1`\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Conv2D ^ T (Transpuesta): 1 filtro de 4x4, stride 2,`padding = 1`\n",
        "* `TanH`\n",
        "* Deberías tener una imagen de 28x28x1, volvé a darle forma de un vector de 784 elementos.\n",
        "\n",
        "Implementar `build_dc_generator` en la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUrq0NkzpwCf"
      },
      "source": [
        "def build_dc_generator(noise_dim=NOISE_DIM):\n",
        "    \"\"\"\n",
        "    Crea y devuelve un modelo PyTorch para el generador DCGAN que implementa\n",
        "    la arquitectura anterior.\n",
        "    \"\"\"\n",
        "    ##############################################################################\n",
        "    # TODO: Implementá la arquitectura                                           #\n",
        "    #                                                                            #\n",
        "    # TIP: nn.Sequential puede ser útil.                                         #\n",
        "    ##############################################################################\n",
        "    # ***** INICIO DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) *****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # ***** FIN DE SU CÓDIGO (NO BORRAR / MODIFICAR ESTA LÍNEA) ***** \n",
        "    ##############################################################################\n",
        "    #                               FIN DE SU CÓDIGO                            #\n",
        "    ##############################################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDNIM_k84fK3"
      },
      "source": [
        "test_g_gan = build_dc_generator().type(dtype)\n",
        "test_g_gan.apply(initialize_weights)\n",
        "\n",
        "fake_seed = torch.randn(batch_size, NOISE_DIM).type(dtype)\n",
        "fake_images = test_g_gan.forward(fake_seed)\n",
        "fake_images.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC2rjl0v4fK3"
      },
      "source": [
        "Verificá la cantidad de parámetros en tu generador por las dudas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo9Gs25l4fK3"
      },
      "source": [
        "def test_dc_generator(true_count=6580801):\n",
        "    model = build_dc_generator(4)\n",
        "    cur_count = count_params(model)\n",
        "    if cur_count != true_count:\n",
        "        print('Número incorrecto de parámetros en el generador. Revisá tu arquitectura.')\n",
        "    else:\n",
        "        print('Número correcto de parámetros en el generador.')\n",
        "\n",
        "test_dc_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7obQfazrqeVP"
      },
      "source": [
        "Corré la siguiente celda para entrenar tu modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "axhi7YHS4fK4"
      },
      "source": [
        "D_DC = build_dc_classifier(batch_size).type(dtype) \n",
        "D_DC.apply(initialize_weights)\n",
        "G_DC = build_dc_generator().type(dtype)\n",
        "G_DC.apply(initialize_weights)\n",
        "\n",
        "D_DC_solver = get_optimizer(D_DC)\n",
        "G_DC_solver = get_optimizer(G_DC)\n",
        "\n",
        "images = run_a_gan(D_DC, G_DC, D_DC_solver, G_DC_solver, discriminator_loss, generator_loss, loader_train, num_epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}