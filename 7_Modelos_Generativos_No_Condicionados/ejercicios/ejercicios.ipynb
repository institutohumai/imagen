{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios Clase 7"
      ],
      "metadata": {
        "id": "bpmb5QjmTqwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este trabajo práctico, nos adentraremos en el fascinante mundo de los VAEs aplicándolos a la generación de imágenes de jugadores de fútbol. Utilizando un conjunto de datos que contiene imágenes de jugadores, construiremos y entrenaremos un modelo de autoencoder variacional que aprenderá a capturar las características esenciales de estas imágenes. Posteriormente, emplearemos el modelo entrenado para generar nuevas imágenes de jugadores, explorando la capacidad de los VAEs para crear contenido visual que no existía previamente."
      ],
      "metadata": {
        "id": "P80T2qYsb6bI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "8ROl6n0vTmqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las siguientes celdas descargan el dataset de jugadores FIFA utilizado en la clase de GANs."
      ],
      "metadata": {
        "id": "gpSVYBhETWv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1zpT6gHzvbr21_Vq4NjpRY0JGSaQOSANa\n",
        "!unzip fifa.zip"
      ],
      "metadata": {
        "id": "27TC12TT975E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torchvision\n",
        "import torch\n",
        "def remove_noise(image):\n",
        "    alpha = image[3, :,:]> 50\n",
        "    alpha = alpha.type(torch.uint8)\n",
        "    noise_filtered = torch.mul(alpha, image)\n",
        "    return noise_filtered[:3,:,:]\n",
        "\n",
        "def read_voc_images(voc_dir, n=-1,  is_train=True):\n",
        "    \"\"\"Read all VOC feature and label images.\"\"\"\n",
        "    files = [os.path.join(voc_dir, file) for file in os.listdir(voc_dir)]\n",
        "    #files = files.sort()\n",
        "    files = sorted(files, key=lambda i: int(os.path.splitext(os.path.basename(i))[0]))\n",
        "    mode = torchvision.io.image.ImageReadMode.RGB_ALPHA\n",
        "    features, labels = [], []\n",
        "    for i, fname in enumerate(files):\n",
        "        l = fname.split(\"/\")\n",
        "        if i==n: break\n",
        "        try:\n",
        "          img = remove_noise(torchvision.io.read_image(os.path.join(\n",
        "            voc_dir, fname)))\n",
        "        except:\n",
        "          continue\n",
        "        features.append(img)\n",
        "        labels.append(int(l[-1][:-4]))\n",
        "    return features, labels\n",
        "\n"
      ],
      "metadata": {
        "id": "cwcEXXm3AGMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "f, l = read_voc_images(\"/content/Images\")\n",
        "names = list(data[\"Name\"])"
      ],
      "metadata": {
        "id": "-61a1JsPFvKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown función show_images\n",
        "from matplotlib import pyplot as plt\n",
        "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
        "    \"\"\"Plot a list of images.\n",
        "\n",
        "    Defined in :numref:`sec_utils`\"\"\"\n",
        "    figsize = (num_cols * scale, num_rows * scale)\n",
        "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
        "        try:\n",
        "            img = img.detach().numpy()\n",
        "        except:\n",
        "            pass\n",
        "        ax.imshow(img)\n",
        "        ax.axes.get_xaxis().set_visible(False)\n",
        "        ax.axes.get_yaxis().set_visible(False)\n",
        "        if titles:\n",
        "            ax.set_title(titles[i])\n",
        "    return axes"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_KxaGY14GSUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = [img.permute(1,2,0) for img in f]\n",
        "show_images(imgs,5,7, scale=2,titles = names);"
      ],
      "metadata": {
        "id": "42zZDPcMGYEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FIFADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_list, labels, names):\n",
        "        super(FIFADataset, self).__init__()\n",
        "        self.img_list = img_list\n",
        "        self.labels = labels\n",
        "        self.names = names\n",
        "        self.transform = torchvision.transforms.Resize((64,64))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_list[idx]/255.0\n",
        "        l  = self.labels[idx]\n",
        "        n  = self.names[idx]\n",
        "        return self.transform(img.type(torch.float32)), l, n"
      ],
      "metadata": {
        "id": "9d4_BV7oTvkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fifa = FIFADataset(f,l,names)\n",
        "batch_size = 256\n",
        "data_iter = torch.utils.data.DataLoader(\n",
        "    fifa, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "ragwrV1AUhX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo"
      ],
      "metadata": {
        "id": "K8QKrOaRTs-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 1"
      ],
      "metadata": {
        "id": "nUIdeIbBVJrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "En esta actividad, crearás dos bloques de construcción de redes neuronales personalizadas utilizando PyTorch. Estos bloques, denominados `AUG_block` y `DEC_block`, serán componentes reutilizables que implementan capas de convolución transpuesta y convolución estándar respectivamente, junto con normalización por lotes y funciones de activación. Sigue los pasos a continuación para crear las clases:\n",
        "\n",
        "1. **Importar las bibliotecas necesarias**: Asegúrate de importar las bibliotecas PyTorch, incluyendo los módulos `nn` y `functional`.\n",
        "\n",
        "2. **Definir la clase `AUG_block`**:\n",
        "   - La clase debe heredar de `nn.Module`.\n",
        "   - En el método `__init__`, inicializa una capa de convolución transpuesta (`nn.ConvTranspose2d`), una capa de normalización por lotes (`nn.BatchNorm2d`) y una función de activación ReLU (`nn.ReLU`).\n",
        "   - Define el método `forward` para aplicar estas capas en secuencia: convolución transpuesta, normalización por lotes y activación ReLU.\n",
        "\n",
        "3. **Definir la clase `DEC_block`**:\n",
        "   - La clase debe heredar de `nn.Module`.\n",
        "   - En el método `__init__`, inicializa una capa de convolución (`nn.Conv2d`), una capa de normalización por lotes (`nn.BatchNorm2d`) y una función de activación LeakyReLU (`nn.LeakyReLU`).\n",
        "   - Define el método `forward` para aplicar estas capas en secuencia: convolución, normalización por lotes y activación LeakyReLU.\n",
        "\n",
        "4. **Parámetros de las clases**:\n",
        "   - Ambas clases deben aceptar los siguientes parámetros en el método `__init__`: `out_channels`, `in_channels` (por defecto 3), `kernel_size` (por defecto 4), `strides` (por defecto 2) y `padding` (por defecto 1).\n",
        "   - La clase `DEC_block` debe aceptar un parámetro adicional `alpha` para la activación LeakyReLU (por defecto 0.2).\n",
        "\n",
        "Asegúrate de seguir las instrucciones y verificar tu código para garantizar que funcione correctamente. ¡Buena suerte!"
      ],
      "metadata": {
        "id": "ocMXvZZ6UbjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AUG_block(nn.Module):\n",
        "    def __init__(self, out_channels, in_channels=3, kernel_size=4, strides=2,\n",
        "                 padding=1, **kwargs):\n",
        "      #inserte su código aquí\n",
        "\n",
        "    def forward(self, X):\n",
        "      #inserte su código aquí\n",
        "\n",
        "class DEC_block(nn.Module):\n",
        "    def __init__(self, out_channels, in_channels=3, kernel_size=4, strides=2,\n",
        "                padding=1, alpha=0.2, **kwargs):\n",
        "      #inserte su código aquí\n",
        "\n",
        "    def forward(self, X):\n",
        "      #inserte su código aquí"
      ],
      "metadata": {
        "id": "qQuXNI5rGQTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 2"
      ],
      "metadata": {
        "id": "BbxG-6OnVbrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "En esta actividad, crearás una clase denominada `Variational_Encoder` utilizando PyTorch. Esta clase implementará un codificador variacional que incluye varias capas convolucionales seguidas de capas lineales para calcular la media y la varianza logarítmica de la distribución latente. Sigue los pasos a continuación para crear la clase:\n",
        "\n",
        "1. **Importar las bibliotecas necesarias**: Asegúrate de importar las bibliotecas PyTorch, incluyendo los módulos `nn` y `functional`.\n",
        "\n",
        "2. **Definir el número de canales de salida inicial `n_G`**: Este valor será utilizado en las capas convolucionales.\n",
        "\n",
        "3. **Definir la clase `Variational_Encoder`**:\n",
        "   - La clase debe heredar de `nn.Module`.\n",
        "   - En el método `__init__`, inicializa una secuencia convolucional (`conv_seq`) utilizando bloques `DEC_block` y capas adicionales:\n",
        "     - Cinco bloques `DEC_block` con canales de salida incrementales (se duplican en cada bloque).\n",
        "     - Una capa `nn.AdaptiveMaxPool2d` para reducir la dimensionalidad espacial.\n",
        "     - Una capa `nn.Flatten` para aplanar el tensor resultante.\n",
        "     - Una capa `nn.LazyLinear` para transformar los datos a la dimensión latente.\n",
        "   - Inicializa dos capas lineales adicionales (`linear3` y `linear4`) usando `nn.LazyLinear` para calcular la media y la varianza logarítmica de la distribución latente.\n",
        "\n",
        "4. **Definir el método `forward`**:\n",
        "   - Aplica la secuencia convolucional a la entrada `x` para obtener `z`.\n",
        "   - Calcula la media (`media`) utilizando una capa lineal.\n",
        "   - Calcula la varianza logarítmica (`log_var`) utilizando otra capa lineal seguida de una activación ReLU.\n",
        "   - Calcula la desviación estándar (`std`) tomando la exponencial de `0.5 * log_var`.\n",
        "   - Genera un tensor de ruido `eps` con la misma forma que `std`.\n",
        "   - Calcula el vector latente (`latente`) utilizando la fórmula `eps * std + media`.\n",
        "   - Retorna una tupla con el vector latente, la media y la varianza logarítmica.\n"
      ],
      "metadata": {
        "id": "5gWCyh3rVNgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_G = 48\n",
        "\n",
        "class Variational_Encoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Variational_Encoder, self).__init__()\n",
        "        self.conv_seq = nn.Sequential(\n",
        "            #inserte su código aquí\n",
        "        )\n",
        "        self.linear3 = #inserte su código aquí\n",
        "        self.linear4 = #inserte su código aquí\n",
        "\n",
        "    def forward(self, x):\n",
        "      #inserte su código aquí"
      ],
      "metadata": {
        "id": "6R7e0BhBGcgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 3"
      ],
      "metadata": {
        "id": "NwpXX2NgZJlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "En esta actividad, crearás una clase denominada `Decoder` utilizando PyTorch. Esta clase implementará un decodificador que incluye capas convolucionales transpuestas y capas lineales para transformar un vector latente en una imagen reconstruida. Sigue los pasos a continuación para crear la clase:\n",
        "\n",
        "1. **Importar las bibliotecas necesarias**: Asegúrate de importar las bibliotecas PyTorch, incluyendo los módulos `nn` y `functional`.\n",
        "\n",
        "2. **Definir el número de canales de salida inicial `n_G`**: Este valor será utilizado en las capas convolucionales transpuestas.\n",
        "\n",
        "3. **Definir la clase `Decoder`**:\n",
        "   - La clase debe heredar de `nn.Module`.\n",
        "   - En el método `__init__`, inicializa una secuencia (`self.seq`) utilizando bloques `AUG_block` y capas adicionales:\n",
        "     - 4 bloques `AUG_block` con canales de salida decrecientes (se reducen a la mitad en cada bloque).\n",
        "     - Una capa `nn.ConvTranspose2d` para transformar los datos a una imagen con 3 canales de salida. En este caso, tiene un tamaño de kernel de 4, un paso (stride) de 2 y un padding de 1.\n",
        "     - Una capa de activación `nn.Sigmoid` para escalar los valores de salida al rango [0, 1].\n",
        "\n",
        "4. **Definir el método `forward`**:\n",
        "   - Aplica la secuencia de capas `self.seq` a la entrada `z` para obtener la imagen reconstruida."
      ],
      "metadata": {
        "id": "EsP1tJYAZFBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            #inserte su código aquí\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, z):\n",
        "      #inserte su código aquí"
      ],
      "metadata": {
        "id": "xBIIXd9pGjx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "k3oIkH-OaNE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Variational_Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Variational_Autoencoder, self).__init__()\n",
        "        self.encoder = Variational_Encoder(latent_dims)\n",
        "        self.decoder = Decoder(latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z, media, log_var = self.encoder(x)\n",
        "        z = z.unsqueeze(2).unsqueeze(3)\n",
        "        return self.decoder(z), media, log_var"
      ],
      "metadata": {
        "id": "fFTYl6vOGoSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def vae_loss(x, x_hat, media, log_var):\n",
        "    reconstruction_loss = F.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "    latent_loss = -0.5 * torch.sum(1 + log_var - log_var.exp() - media.pow(2))\n",
        "    return reconstruction_loss + latent_loss"
      ],
      "metadata": {
        "id": "IEkQvzBHHCIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(autoencoder, data, epochs=40):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        L = 0.0\n",
        "        N = 0\n",
        "        for x, _, _ in data:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat, media, std = autoencoder(x)\n",
        "            l = vae_loss(x,x_hat, media, std)\n",
        "            l.backward()\n",
        "            opt.step()\n",
        "            L += l.sum()\n",
        "            N += l.numel()\n",
        "        print(f'epoch {epoch + 1}, loss {(L/N):f}')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "latent_dims = 500\n",
        "vae = Variational_Autoencoder(latent_dims).to(device) # GPU\n",
        "\n",
        "train(vae, data_iter)"
      ],
      "metadata": {
        "id": "eHmPXb-yHGX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpolación"
      ],
      "metadata": {
        "id": "wpjvEXuEamXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 4"
      ],
      "metadata": {
        "id": "x3jd2E-fa0UA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "En esta actividad, implementarás una función denominada `model_interp` utilizando PyTorch. Esta función generará una interpolación lineal entre dos imágenes comprimidas por un modelo de autoencoder variacional y luego decodificará estas interpolaciones para obtener nuevas imágenes. Sigue los pasos a continuación para crear la función:\n",
        "\n",
        "1. **Definir la función `model_interp`**:\n",
        "   - La función debe aceptar cuatro parámetros:\n",
        "     - `model`: el modelo de autoencoder variacional que será utilizado.\n",
        "     - `index1`: el índice de la primera imagen en el conjunto de datos.\n",
        "     - `index2`: el índice de la segunda imagen en el conjunto de datos.\n",
        "     - `size` (opcional, por defecto 10): el número de interpolaciones que deseas generar entre las dos imágenes.\n",
        "\n",
        "2. **Obtener las imágenes del conjunto de datos**:\n",
        "   - Usa los índices `index1` y `index2` para obtener las dos imágenes del conjunto de datos `fifa`.\n",
        "   - Transfiere las imágenes al dispositivo adecuado (`device`) y agrega una dimensión adicional para que sean compatibles con el modelo.\n",
        "\n",
        "3. **Codificar las imágenes**:\n",
        "   - Pasa las dos imágenes a través del codificador del modelo para obtener sus representaciones comprimidas (`img1_compressed` y `img2_compressed`).\n",
        "\n",
        "4. **Generar interpolaciones**:\n",
        "   - Utiliza una función auxiliar `get_interp` (que se da implementada) para generar una interpolación lineal entre las dos representaciones comprimidas.\n",
        "\n",
        "5. **Preparar las interpolaciones para el decodificador**:\n",
        "   - Convierte las interpolaciones generadas a un tensor de PyTorch.\n",
        "   - Ajusta las dimensiones del tensor para que sean compatibles con el decodificador del modelo.\n",
        "\n",
        "6. **Decodificar las interpolaciones**:\n",
        "   - Pasa las interpolaciones a través del decodificador del modelo para obtener las imágenes artificiales generadas.\n",
        "\n",
        "7. **Retornar las imágenes generadas**.\n",
        "\n",
        "\n",
        "Asegúrate de seguir las instrucciones y verificar tu código para garantizar que funcione correctamente. ¡Buena suerte!"
      ],
      "metadata": {
        "id": "oq6lZPzjaq23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_interp(v1, v2, n):\n",
        "  if not v1.shape == v2.shape:\n",
        "    raise Exception('Different vector size')\n",
        "\n",
        "  v1 = v1.to(\"cpu\")\n",
        "  v2 = v2.to(\"cpu\")\n",
        "\n",
        "  return np.array([np.linspace(v1[i], v2[i], n+2) for i in range(v1.shape[0])]).T\n",
        "\n",
        "\n",
        "\n",
        "def model_interp(model, index1, index2, size = 10):\n",
        "  #inserte su código aquí\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nT62U2KUOWGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Función para mostrar resultados\n",
        "def show_interp(imgs, index1, index2, titles=None, scale=1.5):\n",
        "    \"\"\"Plot a list of images.\n",
        "\n",
        "    Defined in :numref:`sec_utils`\"\"\"\n",
        "    figsize = (12 * scale, 1 * scale)\n",
        "    _, axes = plt.subplots(1, 12, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
        "        try:\n",
        "            img = img.detach().numpy()\n",
        "        except:\n",
        "            pass\n",
        "        if i==0:\n",
        "            ax.set_title(titles[index1])\n",
        "            ax.imshow(fifa[index1][0].permute(1,2,0).cpu().detach().numpy())\n",
        "        elif i==11:\n",
        "            ax.set_title(titles[index2])\n",
        "            ax.imshow(fifa[index2][0].permute(1,2,0).cpu().detach().numpy())\n",
        "        else:\n",
        "          ax.imshow(img)\n",
        "          ax.axes.get_xaxis().set_visible(False)\n",
        "          ax.axes.get_yaxis().set_visible(False)\n",
        "    return axes"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y1Rs6768a8UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index1 = 0\n",
        "index2 = 1\n",
        "interp_result = model_interp(model = vae, index1 = index1, index2 = index2).unbind(0)\n",
        "imgs = [img.permute(1,2,0).cpu() for img in interp_result]\n",
        "show_interp(imgs,index1,index2, scale=2, titles = names);"
      ],
      "metadata": {
        "id": "0N8W5qfXRTth"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}