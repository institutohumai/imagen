{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/CV/5_Deteccion_Objetos/ejercicios/ejercicios.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"
      ],
      "metadata": {
        "id": "rfB-_1RztvN5"
      },
      "id": "rfB-_1RztvN5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detección de objetos"
      ],
      "metadata": {
        "id": "JZp1fZt1lRuJ"
      },
      "id": "JZp1fZt1lRuJ"
    },
    {
      "cell_type": "markdown",
      "id": "323ad4ea",
      "metadata": {
        "origin_pos": 0,
        "id": "323ad4ea"
      },
      "source": [
        "## Data Augmentation.\n",
        "\n",
        "En la clase, vimos como generar un modelo de detección de bananas. Sin embargo el modelo tiene un problema\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/humai-datasets/imagenes/imagen/5_Deteccion_Objetos/MQydvw9.png\" width=\"600\" />\n",
        "\n",
        "Nuestro modelo tiene problemas para detectar bananas no orientdas a la izquierda. Esto se debe a que nuestro dataset tiene mayoritariamente bananas curvadas a las izquierda y en mucha menor medida otras orientaciones. \n",
        "\n",
        "Para corregir esto, manipularemos las imagenes para crear más ejemplos en nuestro dataset. De esta manera pretendemos igualmente representadas bananas orientadas a la izquierda, a la derecha, hacia arriba y hacia abajo.\n",
        "\n",
        "Primero empezaremos trayendo todo el código que ya tenemos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Código Importado"
      ],
      "metadata": {
        "id": "nh9ANrEyNtlT"
      },
      "id": "nh9ANrEyNtlT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33817e0d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:13:34.210206Z",
          "iopub.status.busy": "2022-09-07T22:13:34.209340Z",
          "iopub.status.idle": "2022-09-07T22:13:36.304603Z",
          "shell.execute_reply": "2022-09-07T22:13:36.303501Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "33817e0d"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:11:24.093830Z",
          "iopub.status.busy": "2022-09-07T22:11:24.093188Z",
          "iopub.status.idle": "2022-09-07T22:11:25.941256Z",
          "shell.execute_reply": "2022-09-07T22:11:25.940113Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "ca71352d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from shutil import unpack_archive\n"
      ],
      "id": "ca71352d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef51939",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:13:36.605322Z",
          "iopub.status.busy": "2022-09-07T22:13:36.604736Z",
          "iopub.status.idle": "2022-09-07T22:13:36.612715Z",
          "shell.execute_reply": "2022-09-07T22:13:36.611683Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "2ef51939"
      },
      "outputs": [],
      "source": [
        "def box_corner_to_center(boxes):\n",
        "    \"\"\"Convert from (upper-left, lower-right) to (center, width, height).\"\"\"\n",
        "    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
        "    cx = (x1 + x2) / 2\n",
        "    cy = (y1 + y2) / 2\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    boxes = torch.stack((cx, cy, w, h), axis=-1)\n",
        "    return boxes\n",
        "\n",
        "def box_center_to_corner(boxes):\n",
        "    \"\"\"Convert from (center, width, height) to (upper-left, lower-right).\"\"\"\n",
        "    cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
        "    x1 = cx - 0.5 * w\n",
        "    y1 = cy - 0.5 * h\n",
        "    x2 = cx + 0.5 * w\n",
        "    y2 = cy + 0.5 * h\n",
        "    boxes = torch.stack((x1, y1, x2, y2), axis=-1)\n",
        "    return boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3be2282",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:13:36.635753Z",
          "iopub.status.busy": "2022-09-07T22:13:36.635282Z",
          "iopub.status.idle": "2022-09-07T22:13:36.640594Z",
          "shell.execute_reply": "2022-09-07T22:13:36.639575Z"
        },
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "id": "f3be2282"
      },
      "outputs": [],
      "source": [
        "def bbox_to_rect(bbox, color):\n",
        "    \"\"\"Convert bounding box to matplotlib format.\"\"\"\n",
        "    # Matplotlib espera un bounding box de la forma \n",
        "    # (esquina superior a la izquierda x, esquina superior a la izquierda y,  ancho, alto)\n",
        "    return plt.Rectangle(\n",
        "        xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1],\n",
        "        fill=False, edgecolor=color, linewidth=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:49.860462Z",
          "iopub.status.busy": "2022-09-07T22:12:49.860059Z",
          "iopub.status.idle": "2022-09-07T22:12:49.872403Z",
          "shell.execute_reply": "2022-09-07T22:12:49.871612Z"
        },
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "2e5dbe30"
      },
      "outputs": [],
      "source": [
        "def multibox_prior(data, sizes, ratios):\n",
        "    \"\"\"Generate anchor boxes with different shapes centered on each pixel.\"\"\"\n",
        "\n",
        "    # obtemos el ancho y el alto de la entrada \n",
        "    in_height, in_width = data.shape[-2:]\n",
        "\n",
        "    # definimos la cantidad de anchor boxes y si usamos GPU o CPU\n",
        "    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\n",
        "    boxes_per_pixel = (num_sizes + num_ratios - 1)\n",
        "    size_tensor = torch.tensor(sizes, device=device) # guardamos s_i\n",
        "    ratio_tensor = torch.tensor(ratios, device=device)# guardamos r_j\n",
        "\n",
        "\n",
        "    # Si consideramos a cada pixel como una unidad $1 x 1$, entonces\n",
        "    # tenemos el centro en (0.5, 0.5)\n",
        "    offset_h, offset_w = 0.5, 0.5\n",
        "    # de esta manera el pixel en 4,5 tiene su centro en 4.5, 5.5\n",
        "\n",
        "    # Queremos que nuestro algorimos sea invariante en escala. \n",
        "    # decir, que el ancho y el alto sea 1, en alguna unidad de medida arbitraria\n",
        "    steps_h = 1.0 / in_height  # eje y\n",
        "    steps_w = 1.0 / in_width  # eje x\n",
        "\n",
        "    # En la siguiente linea comentado, agarramos un tensor de la forma:\n",
        "    #    [0, 1, 2, 3, ..., in_height - 1]\n",
        "    # Luego lo escaleamos haciendo que el alto y el ancho de la imagen sea 1\n",
        "    #    center_h = (torch.arange(in_height, device=device) + offset_h)\n",
        "    #    center_h = center_h * steps_h\n",
        "    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\n",
        "    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\n",
        "\n",
        "    # Creamos dos vectores, shift_y y shift_x\n",
        "    # En todos los casos shift_y[i], shift_x[i] coresponde al centro\n",
        "    # con coordenadas x_i, y_i\n",
        "    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')\n",
        "    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n",
        "\n",
        "    # Generamos el ancho y el alto de cada anchor box\n",
        "    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n",
        "                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\\\n",
        "                   * in_height / in_width  # Handle rectangular inputs\n",
        "    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\n",
        "                   sizes[0] / torch.sqrt(ratio_tensor[1:])))\n",
        "    ########\n",
        "    # Hasta aqui hemos generado anchor boxes en la representación\n",
        "    #     x_centro, y_centro, ancho, alto\n",
        "\n",
        "    # Podemos modificara estos valores para devolverlos en la representación:\n",
        "    #     x_superior_izq, y_superior_izq, x_inferior_der, y_inferior_der\n",
        "    # Luego, a partir de los anchos y altos, preparamos nuevos tensores\n",
        "    # para luego sumar los centros de nuestros anchor boxes. \n",
        "    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(\n",
        "                                        in_height * in_width, 1) / 2\n",
        "\n",
        "    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],\n",
        "                dim=1).repeat_interleave(boxes_per_pixel, dim=0)\n",
        "\n",
        "    output = out_grid + anchor_manipulations\n",
        "    return output.unsqueeze(0)"
      ],
      "id": "2e5dbe30"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:49.988070Z",
          "iopub.status.busy": "2022-09-07T22:12:49.987291Z",
          "iopub.status.idle": "2022-09-07T22:12:49.998877Z",
          "shell.execute_reply": "2022-09-07T22:12:49.997497Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "457002d1"
      },
      "outputs": [],
      "source": [
        "def show_bboxes(axes, bboxes, labels=None, colors=None):\n",
        "    \"\"\"Show bounding boxes.\"\"\"\n",
        "\n",
        "# La mayoria de los que hacemos aquí es preparar las entradas para luego \n",
        "# graficarlas en matplotlib. \n",
        "# De hecho axes es una clase creada por matplotlib.\n",
        "\n",
        "    def make_list(obj, default_values=None):\n",
        "        if obj is None:\n",
        "            obj = default_values\n",
        "        elif not isinstance(obj, (list, tuple)):\n",
        "            obj = [obj]\n",
        "        return obj\n",
        "\n",
        "    labels = make_list(labels)\n",
        "    colors = make_list(colors, ['b', 'g', 'r', 'm', 'c'])\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        color = colors[i % len(colors)]\n",
        "        rect = bbox_to_rect(bbox.detach(), color)\n",
        "        axes.add_patch(rect)\n",
        "        if labels and len(labels) > i:\n",
        "            text_color = 'k' if color == 'w' else 'w'\n",
        "            axes.text(rect.xy[0], rect.xy[1], labels[i],\n",
        "                      va='center', ha='center', fontsize=9, color=text_color,\n",
        "                      bbox=dict(facecolor=color, lw=0))"
      ],
      "id": "457002d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:50.417794Z",
          "iopub.status.busy": "2022-09-07T22:12:50.417521Z",
          "iopub.status.idle": "2022-09-07T22:12:50.424210Z",
          "shell.execute_reply": "2022-09-07T22:12:50.423449Z"
        },
        "origin_pos": 17,
        "tab": [
          "pytorch"
        ],
        "id": "2499b66d"
      },
      "outputs": [],
      "source": [
        "def box_iou(boxes1, boxes2):\n",
        "    \"\"\"Compute pairwise IoU across two lists of anchor or bounding boxes.\"\"\"\n",
        "\n",
        "    # funcion anónima para cálculo de areas.\n",
        "    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *\n",
        "                              (boxes[:, 3] - boxes[:, 1]))\n",
        "    \n",
        "    # Calculamos las areas de los boxes que recibiemos.\n",
        "    areas1 = box_area(boxes1)\n",
        "    areas2 = box_area(boxes2)\n",
        "\n",
        "    # Analizamos las esquinas superiores izquierdas de las dos cajas \n",
        "    # Nos quedamos con la que está más abajo y más a la derecha\n",
        "    inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])\n",
        "\n",
        "    # Analizamos las esquinas inferiores derechas de las dos cajas \n",
        "    # Nos quedamos con la que está más arriba y más a la izqueirda\n",
        "    inter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])\n",
        "\n",
        "    # A partir de las esquinas elegidas, restamos sus coordenadas.\n",
        "    # Si la diferencia es negativa, devolvemos 0 (el método clamp hace esto)\n",
        "    inters = (inter_lowerrights - inter_upperlefts).clamp(min=0)\n",
        "\n",
        "    # Calculamos el area de la intersección\n",
        "    inter_areas = inters[:, :, 0] * inters[:, :, 1]\n",
        "    # Calculamos el area de la union\n",
        "    union_areas = areas1[:, None] + areas2 - inter_areas\n",
        "    return inter_areas / union_areas"
      ],
      "id": "2499b66d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:50.428657Z",
          "iopub.status.busy": "2022-09-07T22:12:50.428389Z",
          "iopub.status.idle": "2022-09-07T22:12:50.435597Z",
          "shell.execute_reply": "2022-09-07T22:12:50.434812Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "id": "2036216f"
      },
      "outputs": [],
      "source": [
        "def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5):\n",
        "    \"\"\"Assign closest ground-truth bounding boxes to anchor boxes.\"\"\"\n",
        "    num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0]\n",
        "\n",
        "    #Calculamos el indice de Jaccard\n",
        "    jaccard = box_iou(anchors, ground_truth)\n",
        "\n",
        "    # Definimos un vector de longitud igual al número de anchor boxes.\n",
        "    # De esta manera, si el i-ésimo elemento es 4, eso significa que \n",
        "    # al anchor box número i, le corresponde la clase 4 de nuestro dataset\n",
        "    # Este vector lo inicializamos en -1\n",
        "    anchors_bbox_map = torch.full((num_anchors,), -1, dtype=torch.long,\n",
        "                                  device=device)\n",
        "\n",
        "    # Guardamos el mayor indice de Jaccard para cada anchor box asi como la \n",
        "    # clase a la que perteneces el bounding box correspondiente.\n",
        "    max_ious, indices = torch.max(jaccard, dim=1)\n",
        "\n",
        "    # Si el indice de Jaccard, no supera nuestro umbral de de referencia \n",
        "    # mantenemos el valor -1 con que que fue inicializado\n",
        "    # Si lo supera, reemplazamos con el valor correspondiente.\n",
        "    anc_i = torch.nonzero(max_ious >= iou_threshold).reshape(-1)\n",
        "    box_j = indices[max_ious >= iou_threshold]\n",
        "    anchors_bbox_map[anc_i] = box_j\n",
        "\n",
        "    # mascaras para descartar filas y columnas del tensor jaccard\n",
        "    col_discard = torch.full((num_anchors,), -1)\n",
        "    row_discard = torch.full((num_gt_boxes,), -1)\n",
        "\n",
        "    for _ in range(num_gt_boxes):\n",
        "        max_idx = torch.argmax(jaccard)  # buscamos el mayor indice de Jaccard\n",
        "        \n",
        "        # La forma con la que devolvemos el tensor con los indices de Jaccard\n",
        "        # Nos obliga a hacer operaciones de división entera y modulo\n",
        "        # para encontrar el número anchor box y de bounding box\n",
        "        box_idx = (max_idx % num_gt_boxes).long()\n",
        "        anc_idx = (max_idx / num_gt_boxes).long()\n",
        "        \n",
        "        anchors_bbox_map[anc_idx] = box_idx ## asgino anchor a grounding truth\n",
        "        jaccard[:, box_idx] = col_discard ## relleno con -1!\n",
        "        jaccard[anc_idx, :] = row_discard\n",
        "    return anchors_bbox_map"
      ],
      "id": "2036216f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:50.440646Z",
          "iopub.status.busy": "2022-09-07T22:12:50.439685Z",
          "iopub.status.idle": "2022-09-07T22:12:50.445803Z",
          "shell.execute_reply": "2022-09-07T22:12:50.444828Z"
        },
        "origin_pos": 22,
        "tab": [
          "pytorch"
        ],
        "id": "2beb2bfe"
      },
      "outputs": [],
      "source": [
        "def offset_boxes(anchors, assigned_bb, eps=1e-6):\n",
        "    \"\"\"Transform for anchor box offsets.\"\"\"\n",
        "    c_anc = box_corner_to_center(anchors)\n",
        "    c_assigned_bb = box_corner_to_center(assigned_bb)\n",
        "    offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]\n",
        "    offset_wh = 5 * torch.log( eps + c_assigned_bb[:, 2:] / c_anc[:, 2:] )\n",
        "    offset = torch.cat([offset_xy, offset_wh], axis=1)\n",
        "    return offset"
      ],
      "id": "2beb2bfe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:50.449682Z",
          "iopub.status.busy": "2022-09-07T22:12:50.449036Z",
          "iopub.status.idle": "2022-09-07T22:12:50.457468Z",
          "shell.execute_reply": "2022-09-07T22:12:50.456718Z"
        },
        "origin_pos": 25,
        "tab": [
          "pytorch"
        ],
        "id": "06395d94"
      },
      "outputs": [],
      "source": [
        "def multibox_target(anchors, labels):\n",
        "    \"\"\"Label anchor boxes using ground-truth bounding boxes.\"\"\"\n",
        "\n",
        "    ## Labels contiene 5 elementos:\n",
        "    #     (clase, x_centro, y_centro, ancho, alto)\n",
        "    batch_size, anchors = labels.shape[0], anchors.squeeze(0)\n",
        "    batch_offset, batch_mask, batch_class_labels = [], [], []\n",
        "    device, num_anchors = anchors.device, anchors.shape[0]\n",
        "\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        label = labels[i, :, :] # agarro una imagen del dataset\n",
        "\n",
        "        # asigno el label correspondiente a cada anchor box\n",
        "        anchors_bbox_map = assign_anchor_to_bbox(\n",
        "            label[:, 1:], anchors, device) \n",
        "            #        ^ ahí tire el label y me quedo con el offset\n",
        "        \n",
        "        # genero una mascara para los offsets a descartar\n",
        "        bbox_mask = ((anchors_bbox_map >= 0).float().unsqueeze(-1)).repeat(\n",
        "            1, 4) ## forma [num_anchor , 4], 1 si tiene label, 0 si es fondo\n",
        "\n",
        "        # Initializo class_labels y assigned_bb\n",
        "        class_labels = torch.zeros(num_anchors, dtype=torch.long,\n",
        "                                   device=device)\n",
        "        assigned_bb = torch.zeros((num_anchors, 4), dtype=torch.float32,\n",
        "                                  device=device)\n",
        "\n",
        "        # A partir la categoría identificada, agarro los anchor boxes de interes\n",
        "        indices_true = torch.nonzero(anchors_bbox_map >= 0) \n",
        "        bb_idx = anchors_bbox_map[indices_true]\n",
        "        class_labels[indices_true] = label[bb_idx, 0].long() + 1 #asigno clase\n",
        "        #                                el + 1 que comentamos ^ \n",
        "        assigned_bb[indices_true] = label[bb_idx, 1:] #asigno offset\n",
        "\n",
        "        # Offset transformation\n",
        "        ## ofset a 0 para background\n",
        "        offset = offset_boxes(anchors, assigned_bb) * bbox_mask ## vale 0 o 1\n",
        "        batch_offset.append(offset.reshape(-1))     #append\n",
        "        batch_mask.append(bbox_mask.reshape(-1))    #append\n",
        "        batch_class_labels.append(class_labels)     #append\n",
        "    bbox_offset = torch.stack(batch_offset)         #stack\n",
        "    bbox_mask = torch.stack(batch_mask)             #stack\n",
        "    class_labels = torch.stack(batch_class_labels)  #stack\n",
        "    return (bbox_offset, bbox_mask, class_labels)"
      ],
      "id": "06395d94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:50.804585Z",
          "iopub.status.busy": "2022-09-07T22:12:50.804066Z",
          "iopub.status.idle": "2022-09-07T22:12:50.809257Z",
          "shell.execute_reply": "2022-09-07T22:12:50.808504Z"
        },
        "origin_pos": 38,
        "tab": [
          "pytorch"
        ],
        "id": "f74619d6"
      },
      "outputs": [],
      "source": [
        "def offset_inverse(anchors, offset_preds):\n",
        "    \"\"\"Predict bounding boxes based on anchor boxes with predicted offsets.\"\"\"\n",
        "    anc = box_corner_to_center(anchors)\n",
        "    pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2]\n",
        "    pred_bbox_wh = torch.exp(offset_preds[:, 2:] / 5) * anc[:, 2:]\n",
        "    pred_bbox = torch.cat((pred_bbox_xy, pred_bbox_wh), axis=1)\n",
        "    predicted_bbox = box_center_to_corner(pred_bbox)\n",
        "    return predicted_bbox"
      ],
      "id": "f74619d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:50.813353Z",
          "iopub.status.busy": "2022-09-07T22:12:50.812916Z",
          "iopub.status.idle": "2022-09-07T22:12:50.820002Z",
          "shell.execute_reply": "2022-09-07T22:12:50.818854Z"
        },
        "origin_pos": 41,
        "tab": [
          "pytorch"
        ],
        "id": "bc5d76d5"
      },
      "outputs": [],
      "source": [
        "def nms(boxes, scores, iou_threshold):\n",
        "    \"\"\"Sort confidence scores of predicted bounding boxes.\"\"\"\n",
        "    B = torch.argsort(scores, dim=-1, descending=True)\n",
        "    keep = []  # Indices a ser devuletos\n",
        "    while B.numel() > 0:\n",
        "        i = B[0]\n",
        "        keep.append(i)\n",
        "        if B.numel() == 1: break\n",
        "        ## Jaccard entre la anchor box de mayor confianza y las demas.\n",
        "        iou = box_iou(boxes[i, :].reshape(-1, 4),\n",
        "                      boxes[B[1:], :].reshape(-1, 4)).reshape(-1)\n",
        "        #                     ^ eliminamos el primero\n",
        "        inds = torch.nonzero(iou <= iou_threshold).reshape(-1)\n",
        "        B = B[inds + 1] # + 1 porque elimine el primero a la entrada de box_iou\n",
        "    return torch.tensor(keep, device=boxes.device)"
      ],
      "id": "bc5d76d5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:12:50.824528Z",
          "iopub.status.busy": "2022-09-07T22:12:50.823654Z",
          "iopub.status.idle": "2022-09-07T22:12:50.835993Z",
          "shell.execute_reply": "2022-09-07T22:12:50.835170Z"
        },
        "origin_pos": 44,
        "tab": [
          "pytorch"
        ],
        "id": "c8bfe6ba"
      },
      "outputs": [],
      "source": [
        "def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5,\n",
        "                       pos_threshold=0.009999999):\n",
        "    \"\"\"Predict bounding boxes using non-maximum suppression.\"\"\"\n",
        "\n",
        "    device, batch_size = cls_probs.device, cls_probs.shape[0]\n",
        "    anchors = anchors.squeeze(0)\n",
        "    num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2]\n",
        "    out = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Tomamos la probabilidad de cada clases y los offsets predichios\n",
        "        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-1, 4)\n",
        "        conf, class_id = torch.max(cls_prob[1:], 0) ## [1:], no nos interesa el background.\n",
        "        predicted_bb = offset_inverse(anchors, offset_pred)\n",
        "        keep = nms(predicted_bb, conf, nms_threshold)\n",
        "\n",
        "        # Buscamos aquellos indices que no fueron seleccionados tras NMS\n",
        "        # todos los indice\n",
        "        all_idx = torch.arange(num_anchors, dtype=torch.long, device=device)\n",
        "        # todos los indices + los que queremos mantere\n",
        "        combined = torch.cat((keep, all_idx))\n",
        "        # los indices que no se repiten, corresponden a fondo.\n",
        "        # por lo tanto no los conservamos\n",
        "        uniques, counts = combined.unique(return_counts=True)\n",
        "        non_keep = uniques[counts == 1] #no conservar\n",
        "        \n",
        "        # actualizamos las clases asignadas y las ordenamos, poniendo primero\n",
        "        # las que no son fondo\n",
        "        all_id_sorted = torch.cat((keep, non_keep))\n",
        "        class_id[non_keep] = -1\n",
        "        class_id = class_id[all_id_sorted]\n",
        "        # tambien ordenamos, CON EL MISMO ORDEN, los de más tensores\n",
        "        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]\n",
        "\n",
        "        # Si la confianza o la probabilidad de acertar a la clase es muy baja\n",
        "        #  la tratamos como si fuera fondo.\n",
        "        below_min_idx = (conf < pos_threshold)\n",
        "        class_id[below_min_idx] = -1\n",
        "        # Pero ahora debemos convertir la probabilidad de ser una clase\n",
        "        # a probabilidad de ser fondo.\n",
        "        conf[below_min_idx] = 1 - conf[below_min_idx] ## confianza de ser background\n",
        "        \n",
        "        # 'empaquetamos' la salida.\n",
        "        pred_info = torch.cat((class_id.unsqueeze(1),\n",
        "                               conf.unsqueeze(1),\n",
        "                               predicted_bb), dim=1)\n",
        "        out.append(pred_info)\n",
        "    return torch.stack(out)"
      ],
      "id": "c8bfe6ba"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1"
      ],
      "metadata": {
        "id": "MCVM3_zLOG-D"
      },
      "id": "MCVM3_zLOG-D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Habíamos presentado un dataset para deteccion de bananas. Este dataset cargaba los datos en un tensor, creaba una clase `Dataset` con los tensores y luego armaba un `Dataloader` para validación y entrenamiento\n",
        "\n",
        "Queremos crear más ejemplos con bananas orientadas en diferentes direcciones. Para esto rotaremos nuestras imagenes en 90°, 180° y 270° y las agregaremos al tensor que almacena los datos.\n",
        "\n",
        "El problema es que ahora, también debemos modificar las coordenadas de nuestras bounding boxes, de lo contrario nuestra función de pérdida puede fallar.\n",
        "\n",
        "Implemente el código que necesita para cargar las imágenes rotadas, así como las correciones necesarias a las coordenadas de las bounding boxes.\n",
        "\n",
        "Las bounding boxes están en la representación:\n",
        "\n",
        "`(x_superior_izq, y_superior_izq, x_inferior_der, y_inferior_der )`"
      ],
      "metadata": {
        "id": "lAroFXfaO2R3"
      },
      "id": "lAroFXfaO2R3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:11:25.953041Z",
          "iopub.status.busy": "2022-09-07T22:11:25.952602Z",
          "iopub.status.idle": "2022-09-07T22:11:25.958939Z",
          "shell.execute_reply": "2022-09-07T22:11:25.958162Z"
        },
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ],
        "id": "quu96RBgmXvb"
      },
      "outputs": [],
      "source": [
        "!wget -O banana-detection.zip http://d2l-data.s3-accelerate.amazonaws.com/banana-detection.zip\n",
        "\n",
        "def augmented_bananas(is_train=True):\n",
        "    \"\"\"Read the banana detection dataset images and labels.\"\"\"\n",
        "    if not os.path.isdir(\"banana-detection\"):\n",
        "        unpack_archive('./banana-detection.zip', extract_dir='./', format='zip')\n",
        "\n",
        "    csv_fname = os.path.join('banana-detection', 'bananas_train' if is_train\n",
        "                             else 'bananas_val', 'label.csv')\n",
        "    csv_data = pd.read_csv(csv_fname)\n",
        "    csv_data = csv_data.set_index('img_name')\n",
        "    images, targets = [], []\n",
        "    for img_name, target in csv_data.iterrows():\n",
        "\n",
        "        # versión sin rotación \n",
        "        X = torchvision.io.read_image(\n",
        "            os.path.join('banana-detection', 'bananas_train' if is_train else\n",
        "                         'bananas_val', 'images', f'{img_name}'))\n",
        "        y = list(target)\n",
        "        images.append(X)\n",
        "        targets.append(y.copy())\n",
        "\n",
        "        # inserte aquí su código para las siguientes rotaciones:\n",
        "\n",
        "        #Rot 90 grados\n",
        "\n",
        "        #Rot 180 grados\n",
        "\n",
        "        #Rot 270 grados\n",
        "\n",
        "    return images, torch.tensor(targets).unsqueeze(1) / 256"
      ],
      "id": "quu96RBgmXvb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de `Dataloader`"
      ],
      "metadata": {
        "id": "pAG-dFVibdPL"
      },
      "id": "pAG-dFVibdPL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:11:25.962448Z",
          "iopub.status.busy": "2022-09-07T22:11:25.961969Z",
          "iopub.status.idle": "2022-09-07T22:11:25.967428Z",
          "shell.execute_reply": "2022-09-07T22:11:25.966672Z"
        },
        "origin_pos": 9,
        "tab": [
          "pytorch"
        ],
        "id": "9mjX4gOEnCMK"
      },
      "outputs": [],
      "source": [
        "class AugmentedBananasDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"A customized dataset to load the banana detection dataset.\"\"\"\n",
        "    def __init__(self, is_train):\n",
        "        self.features, self.labels = augmented_bananas(is_train)\n",
        "        print('read ' + str(len(self.features)) + (f' training examples' if\n",
        "              is_train else f' validation examples'))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.features[idx].float(), self.labels[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)"
      ],
      "id": "9mjX4gOEnCMK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:11:25.970712Z",
          "iopub.status.busy": "2022-09-07T22:11:25.970239Z",
          "iopub.status.idle": "2022-09-07T22:11:25.974756Z",
          "shell.execute_reply": "2022-09-07T22:11:25.973979Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "f96b7029"
      },
      "outputs": [],
      "source": [
        "def load_augmented_bananas(batch_size):\n",
        "    \"\"\"Load the banana detection dataset.\"\"\"\n",
        "    train_iter = torch.utils.data.DataLoader(AugmentedBananasDataset(is_train=True),\n",
        "                                             batch_size, shuffle=True)\n",
        "    val_iter = torch.utils.data.DataLoader(AugmentedBananasDataset(is_train=False),\n",
        "                                           batch_size)\n",
        "    return train_iter, val_iter"
      ],
      "id": "f96b7029"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizador de imágenes"
      ],
      "metadata": {
        "id": "Lyd8CID0nLoo"
      },
      "id": "Lyd8CID0nLoo"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
        "    \"\"\"Plot a list of images.\"\"\"\n",
        "    figsize = (num_cols * scale, num_rows * scale)\n",
        "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
        "        try:\n",
        "            img = img.detach()\n",
        "        except:\n",
        "            pass\n",
        "        ax.imshow(img)\n",
        "        ax.axes.get_xaxis().set_visible(False)\n",
        "        ax.axes.get_yaxis().set_visible(False)\n",
        "        if titles:\n",
        "            ax.set_title(titles[i])\n",
        "    return axes\n"
      ],
      "metadata": {
        "id": "XMCpEydWce3N"
      },
      "id": "XMCpEydWce3N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "Si la rotación está funcionando de la manera correcta, debería poder visualizar las imagenes con sos bounding boxes rotadas en los siguientes gráficos.\n",
        "\n",
        "Utilice el siguiente código para verificar que las imágenes se hayan generado correctamente y tengan las bounding boxes correctas.\n",
        "\n",
        "1. ¿Qué valor debe tener `batch size` para visualizar 4 imágenes con las 4 rotaciones aplicadas?\n",
        "2. De los dos `Dataloader` creados, ¿cual nos permite ver la misma imágen con sus rotaciones? ¿Como evitamos que el `Dataloader` desordene las imágenes?"
      ],
      "metadata": {
        "id": "Lv2Z0qQbSWoA"
      },
      "id": "Lv2Z0qQbSWoA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:11:32.954584Z",
          "iopub.status.busy": "2022-09-07T22:11:32.954020Z",
          "iopub.status.idle": "2022-09-07T22:11:33.549713Z",
          "shell.execute_reply": "2022-09-07T22:11:33.548605Z"
        },
        "origin_pos": 17,
        "tab": [
          "pytorch"
        ],
        "id": "3cacc0ea"
      },
      "outputs": [],
      "source": [
        "# 1. Defina el valor de la variable batch_size\n",
        "batch_size =  None\n",
        "\n",
        "edge_size = 256\n",
        "train_iter, val_iter = load_augmented_bananas(batch_size)\n",
        "batch_train = next(iter(train_iter))\n",
        "batch_val = next(iter(val_iter))\n",
        "\n",
        "# 2. Defina minilote a usar dataloader a utilizar\n",
        "batch = None\n",
        "\n",
        "imgs = (batch[0].permute(0, 2, 3, 1)) / 255\n",
        "axes = show_images(imgs, 4, 4, scale=2)\n",
        "for ax, label in zip(axes, batch[1]):\n",
        "    show_bboxes(ax, [label[0][1:5] * edge_size], colors=['w'])"
      ],
      "id": "3cacc0ea"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3\n",
        "\n",
        "Es posible que las transformaciones aplicadas a las bounding boxes sean incorrectas, pesar de que las imagenes anteriores se ven correctamente con sus bounding boxes\n",
        "\n",
        "Esto puede deberse a que durante la rotación, pasamos de tener la esquina superior izquierda y la inferior derecha, a tener las superior derecha y las inferior izquierda.\n",
        "\n",
        "Utilice el siguiente código para verificar que esto no ocurra. Si su transformación de coordenadas actúa correctamente, debería obtener a la salida `tensor(True)`\n",
        "\n",
        "A partir de la variable `batch` del punto anterior defina la variable `boxes` que contiene las bounding boxes de nuestra etiqueta.\n",
        "\n",
        "Recuerde que \n",
        "\n",
        "* La varaible `batch` es un par con dos elementos\n",
        "  * El primer elemento es la imagen RGB\n",
        "  * El segunda elemento es nuestra etiqueta.\n",
        "    * La etiqueta es un tensor de la forma \n",
        "\n",
        "      `[tamaño de minilote, número de objetos a detectar, 5]`\n",
        "\n",
        "      ¿Cuántos objetos estamos detectando?\n",
        "      ¿A que se corresponden esos 5 valores?\n",
        "* La función `offset_boxes` recibe un tensor de la forma\n",
        "\n",
        "    `[tamaño de minilote * número de objetos a detectar, 4]`\n",
        "    \n",
        "  ¿Cuáles son los 4 de los 5 valores anteriores que debemos usar en la función `offset_boxes` ?\n"
      ],
      "metadata": {
        "id": "UzzIGHIqVbcM"
      },
      "id": "UzzIGHIqVbcM"
    },
    {
      "cell_type": "code",
      "source": [
        "# defina la varaible boxes\n",
        "boxes = None\n",
        "\n",
        "centered_boxes = box_corner_to_center(boxes)\n",
        "offsets = offset_boxes(centered_boxes[0].unsqueeze(0),centered_boxes)\n",
        "print(torch.isnan(offsets).sum() == 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VCYwjjntMLJ",
        "outputId": "74ef9257-c5ed-4448-9dc5-b7e33c84203a"
      },
      "id": "4VCYwjjntMLJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "vOuMN2MgMt6P"
      },
      "id": "vOuMN2MgMt6P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:06.943195Z",
          "iopub.status.busy": "2022-09-07T22:21:06.942646Z",
          "iopub.status.idle": "2022-09-07T22:21:09.094249Z",
          "shell.execute_reply": "2022-09-07T22:21:09.093374Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "1a89589a"
      },
      "outputs": [],
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "def cls_predictor(num_inputs, num_anchors, num_classes):\n",
        "    return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1),\n",
        "                     kernel_size=3, padding=1)"
      ],
      "id": "1a89589a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.098898Z",
          "iopub.status.busy": "2022-09-07T22:21:09.098267Z",
          "iopub.status.idle": "2022-09-07T22:21:09.102842Z",
          "shell.execute_reply": "2022-09-07T22:21:09.101984Z"
        },
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "209d5804"
      },
      "outputs": [],
      "source": [
        "def bbox_predictor(num_inputs, num_anchors):\n",
        "    return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1)"
      ],
      "id": "209d5804"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.106493Z",
          "iopub.status.busy": "2022-09-07T22:21:09.106031Z",
          "iopub.status.idle": "2022-09-07T22:21:09.122114Z",
          "shell.execute_reply": "2022-09-07T22:21:09.121292Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "35d00416"
      },
      "outputs": [],
      "source": [
        "def forward(x, block):\n",
        "    return block(x)\n"
      ],
      "id": "35d00416"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.125919Z",
          "iopub.status.busy": "2022-09-07T22:21:09.125431Z",
          "iopub.status.idle": "2022-09-07T22:21:09.130407Z",
          "shell.execute_reply": "2022-09-07T22:21:09.129632Z"
        },
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ],
        "id": "2d265ad5"
      },
      "outputs": [],
      "source": [
        "def flatten_pred(pred):\n",
        "    return torch.flatten(pred.permute(0, 2, 3, 1), start_dim=1)\n",
        "\n",
        "def concat_preds(preds):\n",
        "    return torch.cat([flatten_pred(p) for p in preds], dim=1)"
      ],
      "id": "2d265ad5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.145409Z",
          "iopub.status.busy": "2022-09-07T22:21:09.144861Z",
          "iopub.status.idle": "2022-09-07T22:21:09.151132Z",
          "shell.execute_reply": "2022-09-07T22:21:09.150002Z"
        },
        "origin_pos": 16,
        "tab": [
          "pytorch"
        ],
        "id": "06e97093"
      },
      "outputs": [],
      "source": [
        "def down_sample_blk(in_channels, out_channels):\n",
        "    blk = []\n",
        "    for _ in range(2):\n",
        "        blk.append(nn.Conv2d(in_channels, out_channels,\n",
        "                             kernel_size=3, padding=1))\n",
        "        blk.append(nn.BatchNorm2d(out_channels))\n",
        "        blk.append(nn.ReLU())\n",
        "        in_channels = out_channels\n",
        "    blk.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*blk)"
      ],
      "id": "06e97093"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.169864Z",
          "iopub.status.busy": "2022-09-07T22:21:09.169359Z",
          "iopub.status.idle": "2022-09-07T22:21:09.209293Z",
          "shell.execute_reply": "2022-09-07T22:21:09.208152Z"
        },
        "origin_pos": 22,
        "tab": [
          "pytorch"
        ],
        "id": "8be30a43",
        "outputId": "2cc86c60-0791-4969-94b2-d874f8d9eaf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "def base_net():\n",
        "    blk = []\n",
        "    num_filters = [3, 16, 32, 64]\n",
        "    for i in range(len(num_filters) - 1):\n",
        "        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))\n",
        "    return nn.Sequential(*blk)"
      ],
      "id": "8be30a43"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.213095Z",
          "iopub.status.busy": "2022-09-07T22:21:09.212462Z",
          "iopub.status.idle": "2022-09-07T22:21:09.218453Z",
          "shell.execute_reply": "2022-09-07T22:21:09.217336Z"
        },
        "origin_pos": 25,
        "tab": [
          "pytorch"
        ],
        "id": "0fb02dc5"
      },
      "outputs": [],
      "source": [
        "def get_blk(i):\n",
        "    if i == 0:\n",
        "        blk = base_net()\n",
        "    elif i == 1:\n",
        "        blk = down_sample_blk(64, 128)\n",
        "    elif i == 4:\n",
        "        blk = nn.AdaptiveMaxPool2d((1,1))\n",
        "    else:\n",
        "        blk = down_sample_blk(128, 128)\n",
        "    return blk"
      ],
      "id": "0fb02dc5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.222043Z",
          "iopub.status.busy": "2022-09-07T22:21:09.221729Z",
          "iopub.status.idle": "2022-09-07T22:21:09.227711Z",
          "shell.execute_reply": "2022-09-07T22:21:09.226565Z"
        },
        "origin_pos": 28,
        "tab": [
          "pytorch"
        ],
        "id": "9f09074a"
      },
      "outputs": [],
      "source": [
        "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
        "    Y = blk(X)\n",
        "    anchors = multibox_prior(Y, sizes=size, ratios=ratio)\n",
        "    cls_preds = cls_predictor(Y)\n",
        "    bbox_preds = bbox_predictor(Y)\n",
        "    return (Y, anchors, cls_preds, bbox_preds)"
      ],
      "id": "9f09074a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.233606Z",
          "iopub.status.busy": "2022-09-07T22:21:09.232702Z",
          "iopub.status.idle": "2022-09-07T22:21:09.239625Z",
          "shell.execute_reply": "2022-09-07T22:21:09.238483Z"
        },
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "id": "6708bdcf"
      },
      "outputs": [],
      "source": [
        "sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],\n",
        "         [0.88, 0.961]]\n",
        "ratios = [[1, 2, 0.5]] * 5\n",
        "num_anchors = len(sizes[0]) + len(ratios[0]) - 1"
      ],
      "id": "6708bdcf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.244156Z",
          "iopub.status.busy": "2022-09-07T22:21:09.243259Z",
          "iopub.status.idle": "2022-09-07T22:21:09.257453Z",
          "shell.execute_reply": "2022-09-07T22:21:09.256427Z"
        },
        "origin_pos": 33,
        "tab": [
          "pytorch"
        ],
        "id": "a58841fa"
      },
      "outputs": [],
      "source": [
        "class TinySSD(nn.Module):\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        super(TinySSD, self).__init__(**kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        idx_to_in_channels = [64, 128, 128, 128, 128]\n",
        "        for i in range(5):\n",
        "            # Equivalent to the assignment statement `self.blk_i = get_blk(i)`\n",
        "            setattr(self, f'blk_{i}', get_blk(i))\n",
        "            setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i],\n",
        "                                                    num_anchors, num_classes))\n",
        "            setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i],\n",
        "                                                      num_anchors))\n",
        "\n",
        "    def forward(self, X):\n",
        "        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5\n",
        "        for i in range(5):\n",
        "            # Here `getattr(self, 'blk_%d' % i)` accesses `self.blk_i`\n",
        "            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(\n",
        "                X, getattr(self, f'blk_{i}'), sizes[i], ratios[i],\n",
        "                getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}'))\n",
        "        anchors = torch.cat(anchors, dim=1)\n",
        "        cls_preds = concat_preds(cls_preds)\n",
        "        cls_preds = cls_preds.reshape(\n",
        "            cls_preds.shape[0], -1, self.num_classes + 1)\n",
        "        bbox_preds = concat_preds(bbox_preds)\n",
        "        return anchors, cls_preds, bbox_preds"
      ],
      "id": "a58841fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 37,
        "id": "6ae5cefc"
      },
      "source": [
        "# Entrenamiento\n"
      ],
      "id": "6ae5cefc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialización del pipeline"
      ],
      "metadata": {
        "id": "OYFND-A5NRtf"
      },
      "id": "OYFND-A5NRtf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:09.775004Z",
          "iopub.status.busy": "2022-09-07T22:21:09.774366Z",
          "iopub.status.idle": "2022-09-07T22:21:14.419098Z",
          "shell.execute_reply": "2022-09-07T22:21:14.418243Z"
        },
        "origin_pos": 38,
        "tab": [
          "pytorch"
        ],
        "id": "2bdb3bcd",
        "outputId": "d09b7c16-83e1-4267-9097-df6c4d8c56c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read 4000 training examples\n",
            "read 400 validation examples\n"
          ]
        }
      ],
      "source": [
        "\n",
        "batch_size = 128\n",
        "train_iter, val_iter = load_augmented_bananas(batch_size)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net = TinySSD(num_classes=1)\n",
        "trainer = torch.optim.SGD(net.parameters(), lr=0.2, weight_decay=5e-4)"
      ],
      "id": "2bdb3bcd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:14.449664Z",
          "iopub.status.busy": "2022-09-07T22:21:14.449163Z",
          "iopub.status.idle": "2022-09-07T22:21:14.455005Z",
          "shell.execute_reply": "2022-09-07T22:21:14.454227Z"
        },
        "origin_pos": 44,
        "tab": [
          "pytorch"
        ],
        "id": "1fec8fd4"
      },
      "outputs": [],
      "source": [
        "cls_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "bbox_loss = nn.L1Loss(reduction='none')\n",
        "\n",
        "def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks):\n",
        "    batch_size, num_classes = cls_preds.shape[0], cls_preds.shape[2]\n",
        "    cls = cls_loss(cls_preds.reshape(-1, num_classes),\n",
        "                   cls_labels.reshape(-1)).reshape(batch_size, -1).mean(dim=1)\n",
        "    bbox = bbox_loss(bbox_preds * bbox_masks,\n",
        "                     bbox_labels * bbox_masks).mean(dim=1)\n",
        "    return cls + bbox"
      ],
      "id": "1fec8fd4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:14.460375Z",
          "iopub.status.busy": "2022-09-07T22:21:14.459765Z",
          "iopub.status.idle": "2022-09-07T22:21:14.464807Z",
          "shell.execute_reply": "2022-09-07T22:21:14.464066Z"
        },
        "origin_pos": 47,
        "tab": [
          "pytorch"
        ],
        "id": "0b000cde"
      },
      "outputs": [],
      "source": [
        "def cls_eval(cls_preds, cls_labels):\n",
        "    # Because the class prediction results are on the final dimension,\n",
        "    # `argmax` needs to specify this dimension\n",
        "    return float((cls_preds.argmax(dim=-1).type(\n",
        "        cls_labels.dtype) == cls_labels).sum())\n",
        "\n",
        "def bbox_eval(bbox_preds, bbox_labels, bbox_masks):\n",
        "    return float((torch.abs((bbox_labels - bbox_preds) * bbox_masks)).sum())"
      ],
      "id": "0b000cde"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "fkmsBHEuNVqz"
      },
      "id": "fkmsBHEuNVqz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:21:14.470092Z",
          "iopub.status.busy": "2022-09-07T22:21:14.469419Z",
          "iopub.status.idle": "2022-09-07T22:22:37.049320Z",
          "shell.execute_reply": "2022-09-07T22:22:37.048361Z"
        },
        "origin_pos": 50,
        "tab": [
          "pytorch"
        ],
        "id": "c6a72eec"
      },
      "outputs": [],
      "source": [
        "num_epochs= 30\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Sum of training accuracy, no. of examples in sum of training accuracy,\n",
        "    # Sum of absolute error, no. of examples in sum of absolute error\n",
        "    cls_err, cls_elem, bbox_mae, bbox_elem = 0, 0, 0, 0\n",
        "    loss, loss_elem = 0, 0\n",
        "    net.train()\n",
        "    for features, target in train_iter:\n",
        "        trainer.zero_grad()\n",
        "        X, Y = features.to(device), target.to(device)\n",
        "        # Generate multiscale anchor boxes and predict their classes and\n",
        "        # offsets\n",
        "        anchors, cls_preds, bbox_preds = net(X)\n",
        "        # Label the classes and offsets of these anchor boxes\n",
        "        bbox_labels, bbox_masks, cls_labels = multibox_target(anchors, Y)\n",
        "        # Calculate the loss function using the predicted and labeled values\n",
        "        # of the classes and offsets\n",
        "        l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels,\n",
        "                      bbox_masks)\n",
        "        loss += l.sum()\n",
        "        loss_elem += l.numel()\n",
        "        l.mean().backward()\n",
        "        trainer.step()\n",
        "        \n",
        "        cls_err += cls_eval(cls_preds, cls_labels)\n",
        "        cls_elem += cls_labels.numel()\n",
        "        bbox_mae += bbox_eval(bbox_preds, bbox_labels, bbox_masks)\n",
        "        bbox_elem += bbox_labels.numel()\n",
        "    cls_err, bbox_mae, loss = 1 - cls_err / cls_elem, bbox_mae / bbox_elem, loss / loss_elem\n",
        "    \n",
        "    \n",
        "    val_loss, val_loss_elem = 0, 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for features, target in val_iter:\n",
        "            trainer.zero_grad()\n",
        "            X, Y = features.to(device), target.to(device)\n",
        "            # Generate multiscale anchor boxes and predict their classes and\n",
        "            # offsets\n",
        "            anchors, cls_preds, bbox_preds = net(X)\n",
        "            # Label the classes and offsets of these anchor boxes\n",
        "            bbox_labels, bbox_masks, cls_labels = multibox_target(anchors, Y)\n",
        "            # Calculate the loss function using the predicted and labeled values\n",
        "            # of the classes and offsets\n",
        "            l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels,\n",
        "                          bbox_masks)\n",
        "            val_loss += l.sum()\n",
        "            val_loss_elem += l.numel()\n",
        "        val_loss = val_loss / val_loss_elem\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(net.state_dict(), 'augmented_banana.pt')\n",
        "\n",
        "\n",
        "    print(f'EPOCH: {epoch + 1}')\n",
        "    print(f'    training loss {loss:.2e}')\n",
        "    print(f'    validation loss {val_loss:.2e}')\n",
        "    print(f'    class err {cls_err:.2e}')\n",
        "    print(f'    bbox mae {bbox_mae:.2e}')\n"
      ],
      "id": "c6a72eec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 51,
        "id": "6fe84754"
      },
      "source": [
        "# Prediccion"
      ],
      "id": "6fe84754"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tratemos de replicar la figura inicial \n",
        "\n",
        "<img src=\"https://storage.googleapis.com/humai-datasets/imagenes/imagen/5_Deteccion_Objetos/MQydvw9.png\" width=\"600\"/>\n",
        "\n",
        "\n",
        "## Ejercicio 4\n",
        "\n",
        "Genere 4 copias de la imagen `banana.jpg`, cada una rotada 0°, 90°, 180° y 270°\n",
        "\n",
        "Luego verifique que las predicciones de nuestro modelo, ahora reconocen orientaciones con un umbral de más del 90%"
      ],
      "metadata": {
        "id": "s9_E1G4kXR_o"
      },
      "id": "s9_E1G4kXR_o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:22:37.054201Z",
          "iopub.status.busy": "2022-09-07T22:22:37.053904Z",
          "iopub.status.idle": "2022-09-07T22:22:37.060938Z",
          "shell.execute_reply": "2022-09-07T22:22:37.060085Z"
        },
        "origin_pos": 53,
        "tab": [
          "pytorch"
        ],
        "id": "0b618594"
      },
      "outputs": [],
      "source": [
        "!wget -O banana.jpg https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/banana.jpg\n",
        "X = torchvision.io.read_image('banana.jpg').unsqueeze(0).float()\n",
        "\n",
        "# implemente las rotaciones en las variables X, X2, X3, X4\n",
        "X = None\n",
        "X2 = None\n",
        "X3 = None\n",
        "X4 = None\n",
        "\n",
        "\n",
        "img = X.squeeze(0).permute(1, 2, 0).long()\n",
        "img2 = X2.squeeze(0).permute(1, 2, 0).long()\n",
        "img3 = X3.squeeze(0).permute(1, 2, 0).long()\n",
        "img4 = X4.squeeze(0).permute(1, 2, 0).long()"
      ],
      "id": "0b618594"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:22:37.065833Z",
          "iopub.status.busy": "2022-09-07T22:22:37.065510Z",
          "iopub.status.idle": "2022-09-07T22:22:37.674117Z",
          "shell.execute_reply": "2022-09-07T22:22:37.672933Z"
        },
        "origin_pos": 56,
        "tab": [
          "pytorch"
        ],
        "id": "675a1527"
      },
      "outputs": [],
      "source": [
        "def predict(X):\n",
        "    net.eval()\n",
        "    anchors, cls_preds, bbox_preds = net(X.to(device))\n",
        "    cls_probs = F.softmax(cls_preds, dim=2).permute(0, 2, 1)\n",
        "    output = multibox_detection(cls_probs, bbox_preds, anchors)\n",
        "    idx = [i for i, row in enumerate(output[0]) if row[0] != -1]\n",
        "    return output[0, idx]\n",
        "\n",
        "net.load_state_dict(torch.load('augmented_banana.pt'))\n",
        "\n",
        "output = predict(X)\n",
        "output2 = predict(X2)\n",
        "output3 = predict(X3)\n",
        "output4 = predict(X4)"
      ],
      "id": "675a1527"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualicemos el resultado"
      ],
      "metadata": {
        "id": "-1EveaJVnXIS"
      },
      "id": "-1EveaJVnXIS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:22:37.679097Z",
          "iopub.status.busy": "2022-09-07T22:22:37.678212Z",
          "iopub.status.idle": "2022-09-07T22:22:38.008960Z",
          "shell.execute_reply": "2022-09-07T22:22:38.007898Z"
        },
        "origin_pos": 59,
        "tab": [
          "pytorch"
        ],
        "id": "e038bbaa"
      },
      "outputs": [],
      "source": [
        "def display(img, output, threshold):\n",
        "    fig = plt.imshow(img)\n",
        "    for row in output:\n",
        "        score = float(row[1])\n",
        "        if score < threshold:\n",
        "            continue\n",
        "        h, w = img.shape[:2]\n",
        "        bbox = [row[2:6] * torch.tensor((w, h, w, h), device=row.device)]\n",
        "        show_bboxes(fig.axes, bbox, '%.2f' % score, 'w')\n"
      ],
      "id": "e038bbaa"
    },
    {
      "cell_type": "code",
      "source": [
        "display(img, output.cpu(), threshold=0.9)"
      ],
      "metadata": {
        "id": "5WXmNKFqEZez"
      },
      "id": "5WXmNKFqEZez",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(img2, output2.cpu(), threshold=0.9)"
      ],
      "metadata": {
        "id": "JsbiDPiaEaN7"
      },
      "id": "JsbiDPiaEaN7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(img3, output3.cpu(), threshold=0.9)"
      ],
      "metadata": {
        "id": "MNq4kdo6puCx"
      },
      "id": "MNq4kdo6puCx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(img4, output4.cpu(), threshold=0.9)"
      ],
      "metadata": {
        "id": "lTZguTJqpt8i"
      },
      "id": "lTZguTJqpt8i",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nh9ANrEyNtlT",
        "pAG-dFVibdPL",
        "vOuMN2MgMt6P",
        "6ae5cefc",
        "OYFND-A5NRtf",
        "fkmsBHEuNVqz"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}